#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VSS ìŠ¤ë§ˆíŠ¸ ì°½ê³  ê´€ë¦¬ ì‹œìŠ¤í…œ
Raw Data í†µí•© ë¶„ì„ ë° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
"""

import pandas as pd
import numpy as np
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any
import warnings
warnings.filterwarnings('ignore')

class WarehouseDataIntegrator:
    def __init__(self, rawdata_path: str = "rawdata"):
        self.rawdata_path = rawdata_path
        self.inbound_data = pd.DataFrame()
        self.outbound_data = pd.DataFrame() 
        self.product_master = pd.DataFrame()
        self.analysis_results = {}
        
    def load_all_csv_files(self):
        """ëª¨ë“  CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰"""
        print("ğŸ” CSV íŒŒì¼ ë¡œë”© ë° ë¶„ì„ ì‹œì‘...")
        
        # ì…ê³  ë°ì´í„° í†µí•©
        inbound_files = [f for f in os.listdir(self.rawdata_path) 
                        if f.startswith('InboundData_') and f.endswith('.csv')]
        
        inbound_dfs = []
        for file in sorted(inbound_files):
            file_path = os.path.join(self.rawdata_path, file)
            df = pd.read_csv(file_path)
            # ë¹ˆ ì»¬ëŸ¼ ì œê±°
            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
            df = df.dropna(how='all', axis=1)
            df['source_file'] = file
            inbound_dfs.append(df)
            print(f"  ğŸ“¦ {file}: {len(df)} ê±´")
            
        if inbound_dfs:
            self.inbound_data = pd.concat(inbound_dfs, ignore_index=True)
            # ë‚ ì§œ ë³€í™˜
            self.inbound_data['Date'] = pd.to_datetime(self.inbound_data['Date'], errors='coerce')
            print(f"âœ… ì´ ì…ê³  ë°ì´í„°: {len(self.inbound_data)} ê±´")
        
        # ì¶œê³  ë°ì´í„° í†µí•©
        outbound_files = [f for f in os.listdir(self.rawdata_path) 
                         if f.startswith('OutboundData_') and f.endswith('.csv')]
        
        outbound_dfs = []
        for file in sorted(outbound_files):
            file_path = os.path.join(self.rawdata_path, file)
            df = pd.read_csv(file_path)
            # ë¹ˆ ì»¬ëŸ¼ ì œê±°
            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
            df = df.dropna(how='all', axis=1)
            df['source_file'] = file
            outbound_dfs.append(df)
            print(f"  ğŸšš {file}: {len(df)} ê±´")
            
        if outbound_dfs:
            self.outbound_data = pd.concat(outbound_dfs, ignore_index=True)
            # ë‚ ì§œ ë³€í™˜
            self.outbound_data['Date'] = pd.to_datetime(self.outbound_data['Date'], errors='coerce')
            print(f"âœ… ì´ ì¶œê³  ë°ì´í„°: {len(self.outbound_data)} ê±´")
        
        # ìƒí’ˆ ë§ˆìŠ¤í„° ë°ì´í„°
        product_file = os.path.join(self.rawdata_path, 'product_data.csv')
        if os.path.exists(product_file):
            self.product_master = pd.read_csv(product_file)
            print(f"âœ… ìƒí’ˆ ë§ˆìŠ¤í„°: {len(self.product_master)} ê±´")
    
    def validate_data_quality(self):
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
        print("\nğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì¤‘...")
        
        validation_results = {
            "product_code_matching": {},
            "date_continuity": {},
            "data_completeness": {},
            "anomaly_detection": {}
        }
        
        # 1. ProductCode ë§¤ì¹­ ê²€ì¦
        if not self.product_master.empty:
            master_codes = set(self.product_master['ProductCode'].astype(str))
            inbound_codes = set(self.inbound_data['ProductCode'].astype(str)) if not self.inbound_data.empty else set()
            outbound_codes = set(self.outbound_data['ProductCode'].astype(str)) if not self.outbound_data.empty else set()
            
            # ë§¤ì¹­ë¥  ê³„ì‚°
            inbound_match_rate = len(inbound_codes & master_codes) / len(inbound_codes) if inbound_codes else 0
            outbound_match_rate = len(outbound_codes & master_codes) / len(outbound_codes) if outbound_codes else 0
            
            validation_results["product_code_matching"] = {
                "master_products": len(master_codes),
                "inbound_products": len(inbound_codes),
                "outbound_products": len(outbound_codes),
                "inbound_match_rate": round(inbound_match_rate * 100, 2),
                "outbound_match_rate": round(outbound_match_rate * 100, 2),
                "unmatched_inbound": list(inbound_codes - master_codes)[:5],
                "unmatched_outbound": list(outbound_codes - master_codes)[:5]
            }
        
        # 2. ë‚ ì§œ ì—°ì†ì„± ê²€ì¦
        if not self.inbound_data.empty:
            inbound_dates = self.inbound_data['Date'].dropna().dt.date.unique()
            outbound_dates = self.outbound_data['Date'].dropna().dt.date.unique() if not self.outbound_data.empty else np.array([])
            
            validation_results["date_continuity"] = {
                "inbound_date_range": f"{min(inbound_dates)} ~ {max(inbound_dates)}" if len(inbound_dates) > 0 else "ì—†ìŒ",
                "outbound_date_range": f"{min(outbound_dates)} ~ {max(outbound_dates)}" if len(outbound_dates) > 0 else "ì—†ìŒ",
                "inbound_unique_dates": len(inbound_dates),
                "outbound_unique_dates": len(outbound_dates),
                "date_gaps": self._find_date_gaps(inbound_dates)
            }
        
        # 3. ë°ì´í„° ì™„ì„±ë„ ê²€ì¦
        validation_results["data_completeness"] = {
            "inbound_missing_values": self.inbound_data.isnull().sum().to_dict() if not self.inbound_data.empty else {},
            "outbound_missing_values": self.outbound_data.isnull().sum().to_dict() if not self.outbound_data.empty else {},
            "product_missing_values": self.product_master.isnull().sum().to_dict() if not self.product_master.empty else {}
        }
        
        self.analysis_results["validation"] = validation_results
        print("âœ… ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ")
        
    def _find_date_gaps(self, dates):
        """ë‚ ì§œ ì—°ì†ì„±ì—ì„œ ë¹ ì§„ ë‚ ì§œ ì°¾ê¸°"""
        if len(dates) < 2:
            return []
        
        sorted_dates = sorted(dates)
        gaps = []
        for i in range(len(sorted_dates) - 1):
            current = sorted_dates[i]
            next_date = sorted_dates[i + 1]
            diff = (next_date - current).days
            if diff > 1:
                gaps.append(f"{current} ~ {next_date} ({diff-1}ì¼ ê°„ê²©)")
        return gaps[:3]  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ
    
    def calculate_inventory(self):
        """ì‹¤ì œ ì¬ê³  ê³„ì‚°"""
        print("\nğŸ§® ì¬ê³  ê³„ì‚° ì¤‘...")
        
        if self.product_master.empty:
            print("âŒ ìƒí’ˆ ë§ˆìŠ¤í„° ë°ì´í„°ê°€ ì—†ì–´ ì¬ê³  ê³„ì‚° ë¶ˆê°€")
            return
        
        inventory_results = []
        
        for _, product in self.product_master.iterrows():
            product_code = str(product['ProductCode'])
            
            # ì´ˆê¸° ì¬ê³ 
            initial_stock = product.get('Start Pallete Qty', 0)
            
            # ì…ê³ ëŸ‰ ê³„ì‚°
            inbound_qty = 0
            if not self.inbound_data.empty:
                product_inbound = self.inbound_data[
                    self.inbound_data['ProductCode'].astype(str) == product_code
                ]
                inbound_qty = product_inbound['PalleteQty'].sum() if not product_inbound.empty else 0
            
            # ì¶œê³ ëŸ‰ ê³„ì‚°
            outbound_qty = 0
            if not self.outbound_data.empty:
                product_outbound = self.outbound_data[
                    self.outbound_data['ProductCode'].astype(str) == product_code
                ]
                outbound_qty = product_outbound['PalleteQty'].sum() if not product_outbound.empty else 0
            
            # í˜„ì¬ ì¬ê³  = ì´ˆê¸°ì¬ê³  + ì…ê³  - ì¶œê³ 
            current_stock = initial_stock + inbound_qty - outbound_qty
            
            # ì¼ë³„ ì…ì¶œê³  ë‚´ì—­
            daily_movements = self._get_daily_movements(product_code)
            
            inventory_data = {
                "product_code": product_code,
                "product_name": product.get('ProductName', ''),
                "unit": product.get('Unit', ''),
                "rack_name": product.get('Rack Name', ''),
                "initial_stock": int(initial_stock),
                "total_inbound": int(inbound_qty),
                "total_outbound": int(outbound_qty),
                "current_stock": int(current_stock),
                "stock_status": "ì¶©ë¶„" if current_stock > 5 else "ë¶€ì¡±" if current_stock > 0 else "ì¬ê³ ì—†ìŒ",
                "turnover_ratio": round(outbound_qty / initial_stock, 2) if initial_stock > 0 else 0,
                "daily_movements": daily_movements
            }
            
            inventory_results.append(inventory_data)
        
        # ë™ë³„ ì§‘ê³„
        rack_summary = self._calculate_rack_summary(inventory_results)
        
        self.analysis_results["inventory"] = {
            "products": inventory_results,
            "rack_summary": rack_summary,
            "summary_stats": self._calculate_summary_stats(inventory_results)
        }
        
        print(f"âœ… {len(inventory_results)}ê°œ ìƒí’ˆ ì¬ê³  ê³„ì‚° ì™„ë£Œ")
    
    def _get_daily_movements(self, product_code: str):
        """ìƒí’ˆë³„ ì¼ë³„ ì…ì¶œê³  ë‚´ì—­"""
        movements = []
        
        # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        all_dates = set()
        if not self.inbound_data.empty:
            inbound_dates = self.inbound_data['Date'].dropna().dt.date
            all_dates.update(inbound_dates)
        if not self.outbound_data.empty:
            outbound_dates = self.outbound_data['Date'].dropna().dt.date
            all_dates.update(outbound_dates)
        
        for date in sorted(all_dates):
            # í•´ë‹¹ ë‚ ì§œ ì…ê³ ëŸ‰
            inbound_qty = 0
            if not self.inbound_data.empty:
                day_inbound = self.inbound_data[
                    (self.inbound_data['ProductCode'].astype(str) == product_code) &
                    (self.inbound_data['Date'].dt.date == date)
                ]
                inbound_qty = day_inbound['PalleteQty'].sum() if not day_inbound.empty else 0
            
            # í•´ë‹¹ ë‚ ì§œ ì¶œê³ ëŸ‰
            outbound_qty = 0
            if not self.outbound_data.empty:
                day_outbound = self.outbound_data[
                    (self.outbound_data['ProductCode'].astype(str) == product_code) &
                    (self.outbound_data['Date'].dt.date == date)
                ]
                outbound_qty = day_outbound['PalleteQty'].sum() if not day_outbound.empty else 0
            
            if inbound_qty > 0 or outbound_qty > 0:  # ì›€ì§ì„ì´ ìˆëŠ” ë‚ ë§Œ ê¸°ë¡
                movements.append({
                    "date": date.strftime("%Y-%m-%d"),
                    "inbound": int(inbound_qty),
                    "outbound": int(outbound_qty),
                    "net_change": int(inbound_qty - outbound_qty)
                })
        
        return movements[:7]  # ìµœëŒ€ 7ì¼ì¹˜ë§Œ
    
    def _calculate_rack_summary(self, inventory_results):
        """ë™ë³„ ì§‘ê³„ ê³„ì‚°"""
        rack_data = {}
        
        for item in inventory_results:
            rack_name = item['rack_name']
            if rack_name not in rack_data:
                rack_data[rack_name] = {
                    "rack_name": rack_name,
                    "product_count": 0,
                    "total_initial_stock": 0,
                    "total_current_stock": 0,
                    "total_inbound": 0,
                    "total_outbound": 0,
                    "low_stock_products": []
                }
            
            rack_data[rack_name]["product_count"] += 1
            rack_data[rack_name]["total_initial_stock"] += item["initial_stock"]
            rack_data[rack_name]["total_current_stock"] += item["current_stock"]
            rack_data[rack_name]["total_inbound"] += item["total_inbound"]
            rack_data[rack_name]["total_outbound"] += item["total_outbound"]
            
            if item["current_stock"] <= 5:
                rack_data[rack_name]["low_stock_products"].append({
                    "product_code": item["product_code"],
                    "product_name": item["product_name"][:30] + "..." if len(item["product_name"]) > 30 else item["product_name"],
                    "current_stock": item["current_stock"]
                })
        
        # ì´ìš©ë¥  ê³„ì‚° (í˜„ì¬ì¬ê³ /ì´ˆê¸°ì¬ê³ )
        for rack in rack_data.values():
            if rack["total_initial_stock"] > 0:
                rack["utilization_rate"] = round(rack["total_current_stock"] / rack["total_initial_stock"] * 100, 2)
            else:
                rack["utilization_rate"] = 0
        
        return list(rack_data.values())
    
    def _calculate_summary_stats(self, inventory_results):
        """ì „ì²´ ìš”ì•½ í†µê³„"""
        total_products = len(inventory_results)
        total_current_stock = sum(item["current_stock"] for item in inventory_results)
        total_inbound = sum(item["total_inbound"] for item in inventory_results)
        total_outbound = sum(item["total_outbound"] for item in inventory_results)
        
        low_stock_count = len([item for item in inventory_results if item["current_stock"] <= 5])
        out_of_stock_count = len([item for item in inventory_results if item["current_stock"] <= 0])
        
        high_turnover_products = sorted(
            [item for item in inventory_results if item["turnover_ratio"] > 0.5],
            key=lambda x: x["turnover_ratio"],
            reverse=True
        )[:5]
        
        return {
            "total_products": total_products,
            "total_current_stock": total_current_stock,
            "total_inbound": total_inbound,
            "total_outbound": total_outbound,
            "net_change": total_inbound - total_outbound,
            "low_stock_count": low_stock_count,
            "out_of_stock_count": out_of_stock_count,
            "low_stock_rate": round(low_stock_count / total_products * 100, 2) if total_products > 0 else 0,
            "high_turnover_products": high_turnover_products
        }
    
    def generate_integrated_json(self, output_file: str = "integrated_warehouse_data.json"):
        """í†µí•© JSON íŒŒì¼ ìƒì„±"""
        print(f"\nğŸ“ í†µí•© JSON íŒŒì¼ ìƒì„±: {output_file}")
        
        # ë©”íƒ€ë°ì´í„°
        metadata = {
            "generated_at": datetime.now().isoformat(),
            "data_period": self._get_data_period(),
            "total_files_processed": len([f for f in os.listdir(self.rawdata_path) if f.endswith('.csv')]),
            "data_quality_score": self._calculate_data_quality_score()
        }
        
        # í†µí•© ë°ì´í„° êµ¬ì¡°
        integrated_data = {
            "metadata": metadata,
            "raw_data_summary": {
                "inbound_records": len(self.inbound_data),
                "outbound_records": len(self.outbound_data),
                "product_master_records": len(self.product_master)
            },
            "data_validation": self.analysis_results.get("validation", {}),
            "inventory_analysis": self.analysis_results.get("inventory", {}),
            "recommendations": self._generate_recommendations()
        }
        
        # JSON íŒŒì¼ ì €ì¥
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(integrated_data, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"âœ… JSON íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_file}")
        return output_file
    
    def _get_data_period(self):
        """ë°ì´í„° ê¸°ê°„ ê³„ì‚°"""
        all_dates = []
        if not self.inbound_data.empty:
            all_dates.extend(self.inbound_data['Date'].dropna().dt.date)
        if not self.outbound_data.empty:
            all_dates.extend(self.outbound_data['Date'].dropna().dt.date)
        
        if all_dates:
            return f"{min(all_dates)} ~ {max(all_dates)}"
        return "ë°ì´í„° ì—†ìŒ"
    
    def _calculate_data_quality_score(self):
        """ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-100)"""
        score = 100
        
        validation = self.analysis_results.get("validation", {})
        
        # ProductCode ë§¤ì¹­ë¥  ë°˜ì˜
        matching = validation.get("product_code_matching", {})
        inbound_match = matching.get("inbound_match_rate", 100)
        outbound_match = matching.get("outbound_match_rate", 100)
        score -= (100 - inbound_match) * 0.3
        score -= (100 - outbound_match) * 0.3
        
        # ë°ì´í„° ì™„ì„±ë„ ë°˜ì˜ (ê²°ì¸¡ì¹˜ê°€ ë§ìœ¼ë©´ ê°ì )
        completeness = validation.get("data_completeness", {})
        # ê°„ë‹¨í•œ ì™„ì„±ë„ ì²´í¬ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
        
        return max(0, min(100, round(score, 1)))
    
    def _generate_recommendations(self):
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        validation = self.analysis_results.get("validation", {})
        inventory = self.analysis_results.get("inventory", {})
        
        # ProductCode ë§¤ì¹­ ë¬¸ì œ
        matching = validation.get("product_code_matching", {})
        if matching.get("inbound_match_rate", 100) < 95:
            recommendations.append({
                "category": "ë°ì´í„° í’ˆì§ˆ",
                "priority": "ë†’ìŒ",
                "issue": "ì…ê³  ë°ì´í„°ì˜ ìƒí’ˆì½”ë“œ ë§¤ì¹­ë¥ ì´ ë‚®ìŒ",
                "recommendation": "ìƒí’ˆ ë§ˆìŠ¤í„°ì™€ ì…ê³  ë°ì´í„°ì˜ ProductCode ì •í•©ì„± í™•ì¸ í•„ìš”"
            })
        
        # ì¬ê³  ë¶€ì¡± ìƒí’ˆ
        summary_stats = inventory.get("summary_stats", {})
        if summary_stats.get("low_stock_count", 0) > 0:
            recommendations.append({
                "category": "ì¬ê³  ê´€ë¦¬",
                "priority": "ì¤‘ê°„",
                "issue": f"{summary_stats['low_stock_count']}ê°œ ìƒí’ˆì´ ì¬ê³  ë¶€ì¡± ìƒíƒœ",
                "recommendation": "ì¬ê³  ë¶€ì¡± ìƒí’ˆì˜ ìš°ì„  ë³´ì¶© ê³„íš ìˆ˜ë¦½ í•„ìš”"
            })
        
        # ë†’ì€ íšŒì „ìœ¨ ìƒí’ˆ
        high_turnover = summary_stats.get("high_turnover_products", [])
        if len(high_turnover) > 0:
            recommendations.append({
                "category": "ìˆ˜ìš” ì˜ˆì¸¡",
                "priority": "ë‚®ìŒ",
                "issue": f"{len(high_turnover)}ê°œ ìƒí’ˆì´ ë†’ì€ íšŒì „ìœ¨ì„ ë³´ì„",
                "recommendation": "ê³ íšŒì „ìœ¨ ìƒí’ˆì˜ ì•ˆì „ì¬ê³  ìˆ˜ì¤€ ì¬ê²€í†  ê¶Œì¥"
            })
        
        return recommendations
    
    def run_full_analysis(self):
        """ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸš€ VSS ì°½ê³  ë°ì´í„° í†µí•© ë¶„ì„ ì‹œì‘\n")
        
        # 1. ë°ì´í„° ë¡œë”©
        self.load_all_csv_files()
        
        # 2. ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        self.validate_data_quality()
        
        # 3. ì¬ê³  ê³„ì‚°
        self.calculate_inventory()
        
        # 4. JSON ìƒì„±
        json_file = self.generate_integrated_json()
        
        print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: {json_file}")
        print(f"ğŸ“ˆ ë‹¤ìŒ ë‹¨ê³„: Gemini AI ì¸ì‚¬ì´íŠ¸ ë¶„ì„")
        
        return json_file, self.analysis_results

if __name__ == "__main__":
    integrator = WarehouseDataIntegrator()
    json_file, results = integrator.run_full_analysis()