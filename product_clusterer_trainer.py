#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VSS ProductClusterer ëª¨ë¸ í›ˆë ¨
Phase 1.2: K-Means í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ í›ˆë ¨ ë° ìµœì í™”
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, calinski_harabasz_score
from sklearn.decomposition import PCA
import json
import joblib
from ml_feature_engineering import ProductFeatureExtractor
import warnings
warnings.filterwarnings('ignore')

class ProductClustererTrainer:
    def __init__(self):
        self.extractor = ProductFeatureExtractor()
        self.features_data = None
        self.best_model = None
        self.best_n_clusters = None
        self.cluster_results = None
        
    def find_optimal_clusters(self, X, max_clusters=8):
        """ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸° (Elbow Method + Silhouette Score)"""
        print("ğŸ” ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ íƒìƒ‰ ì¤‘...")
        
        K_range = range(2, max_clusters + 1)
        inertias = []
        silhouette_scores = []
        calinski_scores = []
        
        for k in K_range:
            # K-Means ëª¨ë¸ í›ˆë ¨
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(X)
            
            # í‰ê°€ ì§€í‘œ ê³„ì‚°
            inertias.append(kmeans.inertia_)
            silhouette_scores.append(silhouette_score(X, cluster_labels))
            calinski_scores.append(calinski_harabasz_score(X, cluster_labels))
            
            print(f"   K={k}: Silhouette={silhouette_scores[-1]:.3f}, Calinski={calinski_scores[-1]:.1f}")
        
        # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì • (Silhouette Score ê¸°ì¤€)
        best_idx = np.argmax(silhouette_scores)
        best_k = K_range[best_idx]
        
        print(f"âœ… ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜: {best_k} (Silhouette Score: {silhouette_scores[best_idx]:.3f})")
        
        return best_k, {
            'K_range': list(K_range),
            'inertias': inertias,
            'silhouette_scores': silhouette_scores,
            'calinski_scores': calinski_scores
        }
    
    def train_kmeans_model(self, X, n_clusters):
        """K-Means ëª¨ë¸ í›ˆë ¨"""
        print(f"\nğŸ¯ K-Means ëª¨ë¸ í›ˆë ¨ ì¤‘ (K={n_clusters})...")
        
        # ëª¨ë¸ í›ˆë ¨
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(X)
        
        # ì„±ëŠ¥ í‰ê°€
        silhouette_avg = silhouette_score(X, cluster_labels)
        calinski_score = calinski_harabasz_score(X, cluster_labels)
        
        print(f"âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        print(f"   - Silhouette Score: {silhouette_avg:.3f}")
        print(f"   - Calinski-Harabasz Score: {calinski_score:.1f}")
        print(f"   - Inertia: {kmeans.inertia_:.1f}")
        
        return kmeans, cluster_labels
    
    def analyze_clusters(self, df, cluster_labels, feature_names):
        """í´ëŸ¬ìŠ¤í„° ë¶„ì„ ë° í•´ì„"""
        print("\nğŸ” í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì¤‘...")
        
        # í´ëŸ¬ìŠ¤í„° ë¼ë²¨ ì¶”ê°€
        df_with_clusters = df.copy()
        df_with_clusters['cluster'] = cluster_labels
        
        cluster_analysis = {}
        
        for cluster_id in range(len(np.unique(cluster_labels))):
            cluster_data = df_with_clusters[df_with_clusters['cluster'] == cluster_id]
            
            # ê¸°ë³¸ í†µê³„
            analysis = {
                'size': len(cluster_data),
                'percentage': len(cluster_data) / len(df) * 100,
                'key_products': [],
                'characteristics': {}
            }
            
            # ì£¼ìš” íŠ¹ì§• ê³„ì‚°
            for feature in ['turnover_ratio', 'business_importance', 'daily_variance']:
                if feature in df.columns:
                    analysis['characteristics'][feature] = {
                        'mean': cluster_data[feature].mean(),
                        'std': cluster_data[feature].std(),
                        'median': cluster_data[feature].median()
                    }
            
            # ëŒ€í‘œ ìƒí’ˆ (business_importance ìƒìœ„ 3ê°œ)
            if 'business_importance' in df.columns:
                top_products = cluster_data.nlargest(3, 'business_importance')
                for _, product in top_products.iterrows():
                    analysis['key_products'].append({
                        'product_code': product.get('product_code', 'Unknown'),
                        'product_name': product.get('product_name', 'Unknown')[:30] + '...',
                        'turnover_ratio': product.get('turnover_ratio', 0),
                        'business_importance': product.get('business_importance', 0)
                    })
            
            cluster_analysis[f"cluster_{cluster_id}"] = analysis
            
            print(f"   Cluster {cluster_id}: {analysis['size']}ê°œ ìƒí’ˆ ({analysis['percentage']:.1f}%)")
        
        return cluster_analysis
    
    def interpret_clusters(self, cluster_analysis):
        """í´ëŸ¬ìŠ¤í„°ì— ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸ ë¶€ì—¬"""
        print("\nğŸ§  í´ëŸ¬ìŠ¤í„° í•´ì„ ì¤‘...")
        
        interpretations = {}
        
        for cluster_id, analysis in cluster_analysis.items():
            characteristics = analysis['characteristics']
            
            # íšŒì „ìœ¨ê³¼ ì¤‘ìš”ë„ ê¸°ì¤€ìœ¼ë¡œ í•´ì„
            turnover_mean = characteristics.get('turnover_ratio', {}).get('mean', 0)
            importance_mean = characteristics.get('business_importance', {}).get('mean', 0)
            variance_mean = characteristics.get('daily_variance', {}).get('mean', 0)
            
            # í´ëŸ¬ìŠ¤í„° ìœ í˜• ê²°ì •
            if turnover_mean > 1.5 and importance_mean > 0.7:
                cluster_type = "í”„ë¦¬ë¯¸ì—„ ê³ íšŒì „"
                strategy = "ìµœìš°ì„  ê´€ë¦¬, ì•ˆì „ì¬ê³  í™•ë³´"
                color = "red"
            elif turnover_mean > 1.0 and importance_mean > 0.5:
                cluster_type = "ì£¼ë ¥ ìƒí’ˆ"
                strategy = "ì •ê¸° ëª¨ë‹ˆí„°ë§, ìˆ˜ìš” ì˜ˆì¸¡ ê°•í™”"
                color = "orange"
            elif turnover_mean < 0.5 and importance_mean < 0.3:
                cluster_type = "ì €í™œë™ ìƒí’ˆ"
                strategy = "ì¬ê³  ìµœì†Œí™”, ê³µê°„ íš¨ìœ¨í™”"
                color = "blue"
            else:
                cluster_type = "ì¼ë°˜ ìƒí’ˆ"
                strategy = "í‘œì¤€ ê´€ë¦¬ ì •ì±… ì ìš©"
                color = "green"
            
            interpretations[cluster_id] = {
                'type': cluster_type,
                'strategy': strategy,
                'color': color,
                'metrics': {
                    'avg_turnover': round(turnover_mean, 2),
                    'avg_importance': round(importance_mean, 2),
                    'avg_variance': round(variance_mean, 2)
                }
            }
            
            print(f"   {cluster_id}: {cluster_type} (íšŒì „ìœ¨: {turnover_mean:.2f})")
        
        return interpretations
    
    def save_model_and_results(self, model, results, interpretations):
        """ëª¨ë¸ê³¼ ê²°ê³¼ ì €ì¥"""
        print("\nğŸ’¾ ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        # ëª¨ë¸ ì €ì¥
        joblib.dump(model, 'trained_product_clusterer.pkl')
        
        # ê²°ê³¼ ì €ì¥
        final_results = {
            'model_info': {
                'model_type': 'KMeans',
                'n_clusters': model.n_clusters,
                'random_state': model.random_state,
                'trained_at': pd.Timestamp.now().isoformat()
            },
            'cluster_analysis': results,
            'cluster_interpretations': interpretations,
            'model_performance': {
                'inertia': model.inertia_,
                'feature_count': len(self.features_data['feature_names'])
            }
        }
        
        with open('product_cluster_results.json', 'w', encoding='utf-8') as f:
            json.dump(final_results, f, ensure_ascii=False, indent=2, default=str)
        
        print("âœ… ì €ì¥ ì™„ë£Œ:")
        print("   - trained_product_clusterer.pkl")
        print("   - product_cluster_results.json")
    
    def train_complete_pipeline(self):
        """ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ ProductClusterer í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹œì‘\n")
        
        # 1. íŠ¹ì§• ì¶”ì¶œ
        print("Phase 1: íŠ¹ì§• ì¶”ì¶œ")
        self.features_data = self.extractor.run_feature_extraction()
        
        X = self.features_data['clustering_features']
        df_full = self.features_data['full_features']
        feature_names = self.features_data['feature_names']
        
        # 2. ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸°
        print(f"\nPhase 2: ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ íƒìƒ‰ (ë°ì´í„°: {X.shape})")
        self.best_n_clusters, optimization_results = self.find_optimal_clusters(X, max_clusters=8)
        
        # 3. ìµœì¢… ëª¨ë¸ í›ˆë ¨
        print(f"\nPhase 3: ìµœì¢… ëª¨ë¸ í›ˆë ¨")
        self.best_model, cluster_labels = self.train_kmeans_model(X, self.best_n_clusters)
        
        # 4. í´ëŸ¬ìŠ¤í„° ë¶„ì„
        print(f"\nPhase 4: í´ëŸ¬ìŠ¤í„° ë¶„ì„")
        cluster_analysis = self.analyze_clusters(df_full, cluster_labels, feature_names)
        
        # 5. í´ëŸ¬ìŠ¤í„° í•´ì„
        print(f"\nPhase 5: ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„")
        interpretations = self.interpret_clusters(cluster_analysis)
        
        # 6. ê²°ê³¼ ì €ì¥
        print(f"\nPhase 6: ê²°ê³¼ ì €ì¥")
        self.save_model_and_results(self.best_model, cluster_analysis, interpretations)
        
        # 7. ìš”ì•½ ì¶œë ¥
        print(f"\nğŸ‰ ProductClusterer í›ˆë ¨ ì™„ë£Œ!")
        print(f"   - ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜: {self.best_n_clusters}")
        print(f"   - í›ˆë ¨ ìƒí’ˆ ìˆ˜: {len(df_full)}")
        print(f"   - ì‚¬ìš© íŠ¹ì§• ìˆ˜: {len(feature_names)}")
        
        print(f"\nğŸ“Š í´ëŸ¬ìŠ¤í„°ë³„ ìš”ì•½:")
        for cluster_id, interp in interpretations.items():
            size = cluster_analysis[cluster_id]['size']
            percentage = cluster_analysis[cluster_id]['percentage']
            print(f"   {cluster_id}: {interp['type']} ({size}ê°œ, {percentage:.1f}%)")
        
        return {
            'model': self.best_model,
            'cluster_analysis': cluster_analysis,
            'interpretations': interpretations,
            'optimization_results': optimization_results,
            'features_data': self.features_data
        }

if __name__ == "__main__":
    # í›ˆë ¨ ì‹¤í–‰
    trainer = ProductClustererTrainer()
    results = trainer.train_complete_pipeline()
    
    print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: main.pyì— API ì—”ë“œí¬ì¸íŠ¸ ì—°ë™")
    print(f"   - ëª¨ë¸ íŒŒì¼: trained_product_clusterer.pkl")
    print(f"   - ê²°ê³¼ íŒŒì¼: product_cluster_results.json")