import pandas as pd
import os
import logging
from typing import Dict, List

# Logger ì„¤ì •
logger = logging.getLogger(__name__)

class DataService:
    def __init__(self):
        self.inbound_data: pd.DataFrame = pd.DataFrame()
        self.outbound_data: pd.DataFrame = pd.DataFrame()
        self.product_master: pd.DataFrame = pd.DataFrame()
        self.data_loaded = False # ë°ì´í„° ë¡œë“œ ì—¬ë¶€ í”Œë˜ê·¸

    async def load_all_data(self, rawdata_path: str = "rawdata"):
        if self.data_loaded:
            logger.info("ë°ì´í„°ê°€ ì´ë¯¸ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return

        logger.info(f"ë°ì´í„° ë¡œë”© ì‹œì‘ from {rawdata_path}...")
        all_inbound_dfs = []
        all_outbound_dfs = []

        for filename in os.listdir(rawdata_path):
            file_path = os.path.join(rawdata_path, filename)
            try:
                if "InboundData" in filename and filename.endswith(".csv"):
                    df = pd.read_csv(file_path)
                    # CSVëŠ” 'Date' ì»¬ëŸ¼ ì‚¬ìš© ê°€ì •
                    all_inbound_dfs.append(df)
                elif "OutboundData" in filename and filename.endswith(".csv"):
                    df = pd.read_csv(file_path)
                    # CSVëŠ” 'Date' ì»¬ëŸ¼ ì‚¬ìš© ê°€ì •
                    all_outbound_dfs.append(df)
                elif "ì…ê³ ë°ì´í„°" in filename and filename.endswith(('.xlsx', '.xls')):
                    df = pd.read_excel(file_path)
                    # Excelì€ 'ê±°ë˜ì¼ì' ì»¬ëŸ¼ì„ 'Date'ë¡œ ë³€ê²½
                    if 'ê±°ë˜ì¼ì' in df.columns: df.rename(columns={'ê±°ë˜ì¼ì': 'Date'}, inplace=True)
                    all_inbound_dfs.append(df)
                elif "ì¶œê³ ë°ì´í„°" in filename and filename.endswith(('.xlsx', '.xls')):
                    df = pd.read_excel(file_path)
                    # Excelì€ 'ê±°ë˜ì¼ì' ì»¬ëŸ¼ì„ 'Date'ë¡œ ë³€ê²½
                    if 'ê±°ë˜ì¼ì' in df.columns: df.rename(columns={'ê±°ë˜ì¼ì': 'Date'}, inplace=True)
                    all_outbound_dfs.append(df)
                elif "product_data" in filename and filename.endswith(".csv"):
                    self.product_master = pd.read_csv(file_path)
                    
                    # CSV íŒŒì¼ë„ Excelê³¼ ë™ì¼í•œ ì»¬ëŸ¼ëª… í†µì¼ ì‘ì—… ìˆ˜í–‰
                    found_stock_column = False
                    # ë‹¤ì–‘í•œ ì¬ê³  ê´€ë ¨ ì»¬ëŸ¼ëª… ìš°ì„  í™•ì¸
                    stock_column_candidates = ['í˜„ì¬ê³ ', 'ì¬ê³ ìˆ˜ëŸ‰', 'ì¬ê³ ', 'Current Stock', 'Stock Quantity', 'Start Pallete Qty']
                    for candidate in stock_column_candidates:
                        if candidate in self.product_master.columns:
                            if candidate != 'í˜„ì¬ê³ ': # ì´ë¯¸ 'í˜„ì¬ê³ 'ì¸ ê²½ìš°ëŠ” rename ë¶ˆí•„ìš”
                                self.product_master.rename(columns={candidate: 'í˜„ì¬ê³ '}, inplace=True)
                            found_stock_column = True
                            break
                    
                    if not found_stock_column:
                        print(f"ê²½ê³ : {filename}ì—ì„œ 'í˜„ì¬ê³ 'ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì ì ˆí•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        if 'í˜„ì¬ê³ ' not in self.product_master.columns:
                            self.product_master['í˜„ì¬ê³ '] = 0 # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # 'ë™ìœ„ì¹˜' ì»¬ëŸ¼ë„ í†µì¼
                    if 'Rack Name' in self.product_master.columns and 'ë™ìœ„ì¹˜' not in self.product_master.columns:
                        self.product_master.rename(columns={'Rack Name': 'ë™ìœ„ì¹˜'}, inplace=True)
                    
                    # 'ProductCode' ì»¬ëŸ¼ë„ í†µì¼
                    if 'ProductCode' in self.product_master.columns and 'ìƒí’ˆì½”ë“œ' not in self.product_master.columns:
                        self.product_master.rename(columns={'ProductCode': 'ìƒí’ˆì½”ë“œ'}, inplace=True)
                    
                    print(f"ìƒí’ˆ ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {filename}")
                elif "ìƒí’ˆë°ì´í„°" in filename and filename.endswith(('.xlsx', '.xls')):
                    self.product_master = pd.read_excel(file_path)
                    
                    found_stock_column = False
                    # ë‹¤ì–‘í•œ ì¬ê³  ê´€ë ¨ ì»¬ëŸ¼ëª… ìš°ì„  í™•ì¸
                    stock_column_candidates = ['í˜„ì¬ê³ ', 'ì¬ê³ ìˆ˜ëŸ‰', 'ì¬ê³ ', 'Current Stock', 'Stock Quantity', 'Start Pallete Qty']
                    for candidate in stock_column_candidates:
                        if candidate in self.product_master.columns:
                            if candidate != 'í˜„ì¬ê³ ': # ì´ë¯¸ 'í˜„ì¬ê³ 'ì¸ ê²½ìš°ëŠ” rename ë¶ˆí•„ìš”
                                self.product_master.rename(columns={candidate: 'í˜„ì¬ê³ '}, inplace=True)
                            found_stock_column = True
                            break
                    
                    if not found_stock_column:
                        print(f"ê²½ê³ : {filename}ì—ì„œ 'í˜„ì¬ê³ 'ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì ì ˆí•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'í˜„ì¬ê³ ' ì»¬ëŸ¼ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        # ë§Œì•½ ì–´ë–¤ ì¬ê³  ì»¬ëŸ¼ë„ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ 'í˜„ì¬ê³ ' ì»¬ëŸ¼ì„ NaNìœ¼ë¡œ ì´ˆê¸°í™”í•˜ê±°ë‚˜ 0ìœ¼ë¡œ ì„¤ì •
                        if 'í˜„ì¬ê³ ' not in self.product_master.columns:
                            self.product_master['í˜„ì¬ê³ '] = 0 # ê¸°ë³¸ê°’ ì„¤ì • ë˜ëŠ” NaN
                    
                    # 'ë™ìœ„ì¹˜' ì»¬ëŸ¼ë„ í†µì¼ (ì˜ˆì‹œ)
                    if 'Rack Name' in self.product_master.columns and 'ë™ìœ„ì¹˜' not in self.product_master.columns:
                        self.product_master.rename(columns={'Rack Name': 'ë™ìœ„ì¹˜'}, inplace=True)
                    if 'ProductCode' in self.product_master.columns and 'ìƒí’ˆì½”ë“œ' not in self.product_master.columns:
                        self.product_master.rename(columns={'ProductCode': 'ìƒí’ˆì½”ë“œ'}, inplace=True)

                    print(f"ìƒí’ˆ ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {filename}")

            except Exception as e:
                print(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ {filename}: {e}")
                continue

        if all_inbound_dfs:
            self.inbound_data = pd.concat(all_inbound_dfs, ignore_index=True)
            # 'Date' ì»¬ëŸ¼ì´ datetime í˜•ì‹ì¸ì§€ í™•ì¸ ë° ë³€í™˜
            if 'Date' in self.inbound_data.columns:
                self.inbound_data['Date'] = pd.to_datetime(self.inbound_data['Date'], errors='coerce')
                # ìœ íš¨í•˜ì§€ ì•Šì€ Date ê°’ (NaT)ì„ ê°€ì§„ í–‰ ì œê±°
                original_rows = len(self.inbound_data)
                self.inbound_data.dropna(subset=['Date'], inplace=True)
                if len(self.inbound_data) < original_rows:
                    logger.info(f"ğŸ“¦ ì…ê³  ë°ì´í„°ì—ì„œ {original_rows - len(self.inbound_data)} ê°œì˜ ìœ íš¨í•˜ì§€ ì•Šì€ 'Date' ê°’ì„ ê°€ì§„ í–‰ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
                # ğŸ”§ ë‚ ì§œë¥¼ í‘œì¤€ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ë²¡í„° DB ê²€ìƒ‰ í˜¸í™˜ì„±)
                self.inbound_data['Date'] = self.inbound_data['Date'].dt.strftime('%Y-%m-%d %H:%M:%S')
            # 'Unnamed:' ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì»¬ëŸ¼ ì œê±°
            self.inbound_data = self.inbound_data.loc[:, ~self.inbound_data.columns.str.startswith('Unnamed:')]
            logger.info(f"ğŸ“¦ ì´ ì…ê³  ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.inbound_data)} ê±´")
        if all_outbound_dfs:
            self.outbound_data = pd.concat(all_outbound_dfs, ignore_index=True)
            # 'Date' ì»¬ëŸ¼ì´ datetime í˜•ì‹ì¸ì§€ í™•ì¸ ë° ë³€í™˜
            if 'Date' in self.outbound_data.columns:
                self.outbound_data['Date'] = pd.to_datetime(self.outbound_data['Date'], errors='coerce')
                # ìœ íš¨í•˜ì§€ ì•Šì€ Date ê°’ (NaT)ì„ ê°€ì§„ í–‰ ì œê±°
                original_rows = len(self.outbound_data)
                self.outbound_data.dropna(subset=['Date'], inplace=True)
                if len(self.outbound_data) < original_rows:
                    logger.info(f"ğŸšš ì¶œê³  ë°ì´í„°ì—ì„œ {original_rows - len(self.outbound_data)} ê°œì˜ ìœ íš¨í•˜ì§€ ì•Šì€ 'Date' ê°’ì„ ê°€ì§„ í–‰ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
                # ğŸ”§ ë‚ ì§œë¥¼ í‘œì¤€ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ë²¡í„° DB ê²€ìƒ‰ í˜¸í™˜ì„±)
                self.outbound_data['Date'] = self.outbound_data['Date'].dt.strftime('%Y-%m-%d %H:%M:%S')
            # 'Unnamed:' ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì»¬ëŸ¼ ì œê±°
            self.outbound_data = self.outbound_data.loc[:, ~self.outbound_data.columns.str.startswith('Unnamed:')]
            logger.info(f"ğŸšš ì´ ì¶œê³  ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.outbound_data)} ê±´")

        if not self.product_master.empty:
            # ProductCodeì™€ ProductName ë¶ˆì¼ì¹˜ í™•ì¸ (ê°„ë‹¨í•œ ê²½ê³ )
            if 'ìƒí’ˆì½”ë“œ' in self.product_master.columns and 'ProductName' in self.product_master.columns:
                unique_codes = self.product_master['ìƒí’ˆì½”ë“œ'].nunique()
                unique_names = self.product_master['ProductName'].nunique()
                if unique_codes != unique_names:
                    print(f"ê²½ê³ : ìƒí’ˆ ë§ˆìŠ¤í„° ë°ì´í„°ì—ì„œ ìƒí’ˆì½”ë“œ({unique_codes}ê°œ)ì™€ ìƒí’ˆëª…({unique_names}ê°œ)ì˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„° ì •í•©ì„± í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")

            # í˜„ì¬ê³ ê°€ ëª¨ë‘ 10ìœ¼ë¡œ ê³ ì •ëœ ê²½ìš° ê²½ê³ 
            if 'í˜„ì¬ê³ ' in self.product_master.columns and (self.product_master['í˜„ì¬ê³ '] == 10).all():
                print("ê²½ê³ : ìƒí’ˆ ë§ˆìŠ¤í„° ë°ì´í„°ì˜ 'í˜„ì¬ê³ ' ì»¬ëŸ¼ ê°’ì´ ëª¨ë‘ 10ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì¬ê³  ë°ì´í„°ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                print("í˜„ì¬ê³  ë°ì´í„°ë¥¼ ì •í™•íˆ ë°˜ì˜í•˜ë ¤ë©´ ì›ë³¸ íŒŒì¼(ì˜ˆ: rawdata/ìƒí’ˆë°ì´í„°.xlsx ë˜ëŠ” product_data.csv)ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.")

        self.data_loaded = True
        # ğŸ“Š ë¡œë“œëœ ë°ì´í„° ë‚ ì§œ ë²”ìœ„ í™•ì¸
        if not self.inbound_data.empty and 'Date' in self.inbound_data.columns:
            inbound_dates = pd.to_datetime(self.inbound_data['Date'], errors='coerce')
            logger.info(f"ğŸ“… ì…ê³  ë°ì´í„° ë‚ ì§œ ë²”ìœ„: {inbound_dates.min()} ~ {inbound_dates.max()}")
            logger.info(f"ğŸ“… ì…ê³  ë°ì´í„° ê³ ìœ  ë‚ ì§œ: {sorted(inbound_dates.dropna().dt.strftime('%Y-%m-%d').unique())}")
        
        if not self.outbound_data.empty and 'Date' in self.outbound_data.columns:
            outbound_dates = pd.to_datetime(self.outbound_data['Date'], errors='coerce')
            logger.info(f"ğŸ“… ì¶œê³  ë°ì´í„° ë‚ ì§œ ë²”ìœ„: {outbound_dates.min()} ~ {outbound_dates.max()}")
            logger.info(f"ğŸ“… ì¶œê³  ë°ì´í„° ê³ ìœ  ë‚ ì§œ: {sorted(outbound_dates.dropna().dt.strftime('%Y-%m-%d').unique())}")
        
        logger.info("ëª¨ë“  ë°ì´í„° ë¡œë”© ì™„ë£Œ.")

    def get_unified_inventory_stats(self):
        """ğŸ“Š í†µí•© ì¬ê³  ê³„ì‚° ë©”ì„œë“œ - ëª¨ë“  ê³„ì‚°ì˜ ë‹¨ì¼ ì†ŒìŠ¤"""
        if not self.data_loaded:
            return {
                "error": "ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                "calculation_method": "none",
                "data_loaded": False
            }
        
        try:
            # ğŸ”§ í†µí•© ê³„ì‚° ë¡œì§
            total_inbound_qty = self.inbound_data['PalleteQty'].sum() if 'PalleteQty' in self.inbound_data.columns else 0
            total_outbound_qty = self.outbound_data['PalleteQty'].sum() if 'PalleteQty' in self.outbound_data.columns else 0
            
            # ğŸ“Š ì¬ê³  ê³„ì‚° ë°©ì‹ ê²°ì • (ì¼ê´€ì„± í™•ë³´)
            stock_column = 'í˜„ì¬ê³ ' if 'í˜„ì¬ê³ ' in self.product_master.columns else 'Start Pallete Qty'
            base_inventory = self.product_master[stock_column].sum() if stock_column in self.product_master.columns else 0
            
            # ğŸ¯ ë‹¨ì¼ ì¬ê³  ê³„ì‚° ë°©ì‹: í˜„ì¬ê³  ì»¬ëŸ¼ ê¸°ì¤€ (ë¡œê·¸ì—ì„œ í™•ì¸ëœ ì‹¤ì œ ë°ì´í„°)
            unified_total_inventory = int(base_inventory)  # í˜„ì¬ê³  ì»¬ëŸ¼ ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            
            # ğŸ“ˆ ë™ë³„ ë°ì´í„° ì¼ê´€ì„± í™•ë³´
            rack_column_options = ['ë™ìœ„ì¹˜', 'Rack Name', 'Rack Code Name']
            rack_column = None
            for col in rack_column_options:
                if col in self.product_master.columns:
                    rack_column = col
                    break
            
            rack_distribution = {}
            if rack_column:
                rack_distribution = self.product_master.groupby(rack_column)[stock_column].sum().to_dict()
            
            return {
                "calculation_method": "unified_current_stock",
                "data_loaded": True,
                "total_inventory": unified_total_inventory,
                "base_inventory": int(base_inventory),
                "total_inbound_qty": int(total_inbound_qty),
                "total_outbound_qty": int(total_outbound_qty),
                "calculated_net_inventory": int(base_inventory + total_inbound_qty - total_outbound_qty),
                "daily_inbound_avg": int(total_inbound_qty / 7) if total_inbound_qty > 0 else 0,
                "daily_outbound_avg": int(total_outbound_qty / 7) if total_outbound_qty > 0 else 0,
                "total_products": len(self.product_master),
                "rack_column_used": rack_column,
                "rack_distribution": rack_distribution,
                "available_racks": list(self.product_master[rack_column].unique()) if rack_column else [],
                "stock_column_used": stock_column
            }
            
        except Exception as e:
            logger.error(f"âŒ í†µí•© ì¬ê³  ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {"error": str(e), "calculation_method": "failed"}

    def get_current_summary(self):
        """í˜„ì¬ ì°½ê³  ìƒíƒœ ìš”ì•½ ì •ë³´ ë°˜í™˜ (í†µí•© ê³„ì‚° ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •)"""
        # ğŸ”„ í†µí•© ê³„ì‚° ë©”ì„œë“œ ì‚¬ìš©
        unified_stats = self.get_unified_inventory_stats()
        
        if "error" in unified_stats:
            return {
                "error": unified_stats["error"],
                "total_products": 0,
                "total_inventory": 0,
                "daily_inbound": 0,
                "daily_outbound": 0
            }
        
        # ğŸ“Š ì¼ê´€ëœ ê²°ê³¼ ë°˜í™˜
        summary = {
            "total_products": unified_stats["total_products"],
            "total_inventory": unified_stats["total_inventory"],  # í†µí•©ëœ ì¬ê³ ëŸ‰ ì‚¬ìš©
            "daily_inbound": unified_stats["daily_inbound_avg"],
            "daily_outbound": unified_stats["daily_outbound_avg"],
            "available_racks": unified_stats["available_racks"],
            "total_inbound_qty": unified_stats["total_inbound_qty"],
            "total_outbound_qty": unified_stats["total_outbound_qty"],
            "calculation_method": unified_stats["calculation_method"]  # ë””ë²„ê¹…ìš©
        }
        
        logger.info(f"ğŸ“Š [UNIFIED] í†µí•© ê³„ì‚° ê²°ê³¼: ì´ì¬ê³ ={summary['total_inventory']}, ì¼í‰ê· ì…ê³ ={summary['daily_inbound']}, ì¼í‰ê· ì¶œê³ ={summary['daily_outbound']}")
        return summary
    
    def calculate_daily_turnover_rate(self):
        """ì¼ë³„ ì¬ê³ íšŒì „ìœ¨ ê³„ì‚° (ìˆ˜ì •ëœ ë¡œì§ - ì‹¤ì œ ìˆ˜ëŸ‰ ê¸°ì¤€)"""
        if not self.data_loaded:
            return 0.0
            
        try:
            # ì´ ì¶œê³ ëŸ‰ (ì‹¤ì œ PalleteQty í•©ê³„)
            total_outbound_qty = self.outbound_data['PalleteQty'].sum() if 'PalleteQty' in self.outbound_data.columns else 0
            
            # í˜„ì¬ ì‹¤ì œ ì¬ê³ ëŸ‰ ê³„ì‚°
            stock_column = 'í˜„ì¬ê³ ' if 'í˜„ì¬ê³ ' in self.product_master.columns else 'Start Pallete Qty'
            start_inventory = self.product_master[stock_column].sum() if stock_column in self.product_master.columns else 0
            total_inbound_qty = self.inbound_data['PalleteQty'].sum() if 'PalleteQty' in self.inbound_data.columns else 0
            current_inventory = start_inventory + total_inbound_qty - total_outbound_qty
            
            # ì¼í‰ê·  ì¶œê³ ëŸ‰ / í˜„ì¬ ì¬ê³ ëŸ‰ = ì¼ë³„ íšŒì „ìœ¨
            daily_avg_outbound = total_outbound_qty / 7
            daily_turnover = daily_avg_outbound / current_inventory if current_inventory > 0 else 0
            
            print(f"ğŸ“Š íšŒì „ìœ¨ ê³„ì‚°: ì¼í‰ê· ì¶œê³ ={daily_avg_outbound}, í˜„ì¬ì¬ê³ ={current_inventory}, íšŒì „ìœ¨={daily_turnover}")
            return round(daily_turnover, 3)
        except Exception as e:
            print(f"íšŒì „ìœ¨ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return 0.0
    
    def calculate_rack_utilization(self):
        """ë™ë³„ í™œìš©ë¥  ê³„ì‚° (í†µí•© ê³„ì‚° ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •)"""
        # ğŸ”„ í†µí•© ê³„ì‚° ë©”ì„œë“œ ì‚¬ìš©
        unified_stats = self.get_unified_inventory_stats()
        
        if "error" in unified_stats:
            logger.error(f"âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {unified_stats['error']}")
            return {}
            
        try:
            # ğŸ“Š í†µí•© ë°ì´í„°ì—ì„œ ë™ë³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            rack_distribution = unified_stats["rack_distribution"]
            rack_column = unified_stats["rack_column_used"]
            total_inventory = unified_stats["total_inventory"]
            
            logger.info(f"ğŸ“Š [UNIFIED_RACK] ì‚¬ìš© ë™ ì»¬ëŸ¼: {rack_column}")
            logger.info(f"ğŸ“Š [UNIFIED_RACK] ë™ë³„ ë¶„í¬: {rack_distribution}")
            
            if not rack_distribution:
                logger.warning("âš ï¸ ë™ë³„ ë¶„í¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {}
            
            # í˜„ì‹¤ì ì¸ ìµœëŒ€ìš©ëŸ‰ ì„¤ì •
            avg_capacity_per_rack = 50  # ë™ë‹¹ í‰ê·  50ê°œ ìš©ëŸ‰
            
            rack_utilization = {}
            total_current_stock = 0
            total_max_capacity = 0
            
            for rack, current_stock in rack_distribution.items():
                current_stock = int(current_stock)
                max_capacity = avg_capacity_per_rack
                utilization_rate = (current_stock / max_capacity) * 100
                
                rack_utilization[rack] = {
                    "current_stock": current_stock,
                    "max_capacity": max_capacity,
                    "utilization_rate": round(utilization_rate, 1)
                }
                
                total_current_stock += current_stock
                total_max_capacity += max_capacity
            
            # ì „ì²´ í™œìš©ë¥  ê³„ì‚°
            overall_utilization = (total_current_stock / total_max_capacity) * 100 if total_max_capacity > 0 else 0
            
            # ğŸ“Š ì¼ê´€ì„± ê²€ì¦
            if total_current_stock != total_inventory:
                logger.warning(f"âš ï¸ [CONSISTENCY_CHECK] ì¬ê³  ë¶ˆì¼ì¹˜ ê°ì§€: ë™ë³„í•©ê³„={total_current_stock} vs í†µí•©ê³„ì‚°={total_inventory}")
            
            logger.info(f"ğŸ“Š [UNIFIED_RACK] ë™ í™œìš©ë¥ : ì „ì²´={overall_utilization:.1f}%, ì´ì¬ê³ ={total_current_stock}, ì´ìš©ëŸ‰={total_max_capacity}")
            
            return rack_utilization
            
        except Exception as e:
            logger.error(f"âŒ ë™ í™œìš©ë¥  ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return {}

    def get_relevant_data(self, intent: str):
        if not self.data_loaded:
            logger.warning("ë°ì´í„°ê°€ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_all_data()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
            return {"context": "ë°ì´í„° ì—†ìŒ"}

        if intent == "inventory":
            return {"inbound": self.inbound_data.to_dict(orient='records'),
                    "outbound": self.outbound_data.to_dict(orient='records'),
                    "product_master": self.product_master.to_dict(orient='records'),
                    "description": "ë™ë³„ ì¬ê³  í˜„í™©ì„ ë¶„ì„í•˜ê¸° ìœ„í•œ ì…ì¶œê³  ë° ìƒí’ˆ ë§ˆìŠ¤í„° ë°ì´í„°ì…ë‹ˆë‹¤."}
        elif intent == "outbound":
            return {"outbound": self.outbound_data.to_dict(orient='records'),
                    "product_master": self.product_master.to_dict(orient='records'),
                    "description": "ì¶œê³ ëŸ‰ ì¶”ì´ ë° ì œí’ˆë³„ ì¶œê³  ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ì…ë‹ˆë‹¤."}
        elif intent == "prediction":
            # ì˜ˆì¸¡ì— í•„ìš”í•œ ë°ì´í„° (ì˜ˆ: ê³¼ê±° ì…ì¶œê³ , ìƒí’ˆ ì •ë³´)ë¥¼ ê°€ê³µí•˜ì—¬ ë°˜í™˜
            return {"inbound": self.inbound_data.to_dict(orient='records'),
                    "outbound": self.outbound_data.to_dict(orient='records'),
                    "product_master": self.product_master.to_dict(orient='records'),
                    "description": "ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ë° ì¶”ë¡ ì— ì‚¬ìš©ë  ë°ì´í„°ì…ë‹ˆë‹¤."}
        else:
            return {"inbound": self.inbound_data.to_dict(orient='records'),
                    "outbound": self.outbound_data.to_dict(orient='records'),
                    "product_master": self.product_master.to_dict(orient='records'),
                    "description": "ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ ëª¨ë“  ê¸°ë³¸ ì°½ê³  ë°ì´í„°ì…ë‹ˆë‹¤."}
    
    def get_product_category_distribution(self):
        """ì‹¤ì œ rawdata ê¸°ë°˜ ì œí’ˆ ì¹´í…Œê³ ë¦¬ ë¶„í¬ ê³„ì‚°"""
        if not self.data_loaded or self.product_master.empty:
            return None
            
        try:
            # ì œí’ˆëª… ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            categories = {
                'ë©´ë¥˜/ë¼ë©´': 0,
                'ìŒë£Œ/ìŒë£Œìˆ˜': 0, 
                'ì¡°ë¯¸ë£Œ/ì–‘ë…': 0,
                'ê³¡ë¬¼/ìŒ€': 0,
                'ìŠ¤ë‚µ/ê³¼ì': 0,
                'ê¸°íƒ€': 0
            }
            
            for _, product in self.product_master.iterrows():
                product_name = str(product.get('ProductName', '')).lower()
                
                # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ë¡œì§
                if any(keyword in product_name for keyword in ['ë¼ë©´', 'ë©´', 'ìš°ë™', 'êµ­ìˆ˜', 'íƒ•ë©´', 'ì‚¬ë°œë©´', 'ì»µë¼ë©´']):
                    categories['ë©´ë¥˜/ë¼ë©´'] += 1
                elif any(keyword in product_name for keyword in ['ì½œë¼', 'ì‚¬ì´ë‹¤', 'ì£¼ìŠ¤', 'ìƒìˆ˜', 'ìŒë£Œ', 'ì»¤í”¼', 'ì°¨', 'íƒ„ì‚°', 'ë“œë§í¬']):
                    categories['ìŒë£Œ/ìŒë£Œìˆ˜'] += 1
                elif any(keyword in product_name for keyword in ['ê°„ì¥', 'ëœì¥', 'ìŒˆì¥', 'ê³ ì¶”ì¥', 'ì„¤íƒ•', 'ì—¿', 'ê°€ë£¨', 'ì†ŒìŠ¤', 'ì–‘ë…', 'ì¡°ë¯¸ë£Œ', 'ì¼€ì°¹']):
                    categories['ì¡°ë¯¸ë£Œ/ì–‘ë…'] += 1
                elif any(keyword in product_name for keyword in ['ìŒ€', 'ë°€ê°€ë£¨', 'ì „ë¶„', 'ì‹œë¦¬ì–¼']):
                    categories['ê³¡ë¬¼/ìŒ€'] += 1
                elif any(keyword in product_name for keyword in ['ê¹¡', 'ìŠ¤ë‚µ', 'ê³¼ì', 'ë°”', 'í¬ëŸ°ì¹˜']):
                    categories['ìŠ¤ë‚µ/ê³¼ì'] += 1
                else:
                    categories['ê¸°íƒ€'] += 1
            
            # ì°¨íŠ¸ìš© ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            result = []
            for category, count in categories.items():
                if count > 0:  # 0ê°œì¸ ì¹´í…Œê³ ë¦¬ëŠ” ì œì™¸
                    result.append({
                        'name': category,
                        'value': count
                    })
            
            # ê°œìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            result.sort(key=lambda x: x['value'], reverse=True)
            
            return result
            
        except Exception as e:
            logger.error(f"ì¹´í…Œê³ ë¦¬ ë¶„í¬ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return None
    
    def get_daily_trends_summary(self):
        """ì‹¤ì œ rawdata ê¸°ë°˜ ì¼ë³„ ì…ì¶œê³  íŠ¸ë Œë“œ ê³„ì‚°"""
        if not self.data_loaded:
            logger.warning("âš ï¸ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
            
        try:
            import pandas as pd
            from datetime import datetime
            
            # ë‚ ì§œë³„ ì…ê³ /ì¶œê³ ëŸ‰ ì§‘ê³„
            daily_trends = []
            
            # ì…ê³ /ì¶œê³  ë°ì´í„° ë‚ ì§œ ì»¬ëŸ¼ íƒ€ì… í™•ì¸ ë° ë³€í™˜
            for data_name, data_df in [("inbound", self.inbound_data), ("outbound", self.outbound_data)]:
                if data_df is not None and not data_df.empty and 'Date' in data_df.columns:
                    # ë‚ ì§œ ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (ë§Œì•½ datetimeì´ë‚˜ ë‹¤ë¥¸ íƒ€ì…ì¸ ê²½ìš°)
                    if data_df['Date'].dtype != 'object':
                        logger.info(f"ğŸ“… {data_name} Date ì»¬ëŸ¼ íƒ€ì… ë³€í™˜: {data_df['Date'].dtype} â†’ string")
                        data_df['Date'] = data_df['Date'].astype(str)
            
            # 2025.01.01 ~ 2025.01.07 ë°ì´í„° ì²˜ë¦¬
            for day in range(1, 8):
                date_str = f"2025.01.{day:02d}"
                date_patterns = [f"2025.01.{day:02d}", f"2025-01-{day:02d}", f"01/{day:02d}/2025", f"2025/01/{day:02d}"]
                
                total_inbound = 0
                total_outbound = 0
                
                # ì…ê³  ë°ì´í„° ì§‘ê³„ (ì•ˆì „í•œ ë‚ ì§œ ë§¤ì¹­)
                if self.inbound_data is not None and not self.inbound_data.empty and 'Date' in self.inbound_data.columns:
                    for pattern in date_patterns:
                        try:
                            inbound_day = self.inbound_data[self.inbound_data['Date'].str.contains(pattern, na=False, regex=False)]
                            if not inbound_day.empty:
                                total_inbound = inbound_day['PalleteQty'].sum() if 'PalleteQty' in inbound_day.columns else 0
                                break
                        except Exception as pattern_error:
                            logger.debug(f"íŒ¨í„´ {pattern} ë§¤ì¹­ ì‹¤íŒ¨: {pattern_error}")
                            continue
                
                # ì¶œê³  ë°ì´í„° ì§‘ê³„ (ì•ˆì „í•œ ë‚ ì§œ ë§¤ì¹­)
                if self.outbound_data is not None and not self.outbound_data.empty and 'Date' in self.outbound_data.columns:
                    for pattern in date_patterns:
                        try:
                            outbound_day = self.outbound_data[self.outbound_data['Date'].str.contains(pattern, na=False, regex=False)]
                            if not outbound_day.empty:
                                total_outbound = outbound_day['PalleteQty'].sum() if 'PalleteQty' in outbound_day.columns else 0
                                break
                        except Exception as pattern_error:
                            logger.debug(f"íŒ¨í„´ {pattern} ë§¤ì¹­ ì‹¤íŒ¨: {pattern_error}")
                            continue
                
                daily_trends.append({
                    'date': date_str,
                    'inbound': int(total_inbound),
                    'outbound': int(total_outbound),
                    'net_change': int(total_inbound - total_outbound)
                })
            
            logger.info(f"âœ… ì¼ë³„ íŠ¸ë Œë“œ ê³„ì‚° ì™„ë£Œ: {len(daily_trends)}ì¼ ë°ì´í„°")
            return daily_trends
            
        except Exception as e:
            logger.error(f"âŒ ì¼ë³„ íŠ¸ë Œë“œ ê³„ì‚° ì˜¤ë¥˜: {e}")
            logger.warning("âš ï¸ ì¼ë³„ íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ, ê¸°ë³¸ê°’ ë°˜í™˜")
            # ê¸°ë³¸ê°’ ë°˜í™˜ (7ì¼ê°„ ë°ì´í„°)
            return [
                {'date': f"2025.01.{day:02d}", 'inbound': 0, 'outbound': 0, 'net_change': 0}
                for day in range(1, 8)
            ] 