"""
ChromaDBë¥¼ í™œìš©í•œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤
"""
import os
import logging
import pandas as pd
from typing import List, Dict, Any, Optional
from datetime import datetime
import json

try:
    import chromadb
    from chromadb.config import Settings
    from sentence_transformers import SentenceTransformer
except ImportError:
    chromadb = None
    SentenceTransformer = None

class VectorDBService:
    """ChromaDBë¥¼ í™œìš©í•œ ì°½ê³  ë°ì´í„° ë²¡í„°í™” ë° ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    def __init__(self, data_service=None, logger=None):
        self.logger = logger or logging.getLogger(__name__)
        self.data_service = data_service
        self.client = None
        self.collection = None
        self.encoder = None
        self.is_initialized = False
        
        if chromadb is None or SentenceTransformer is None:
            self.logger.warning("âš ï¸ ChromaDB ë˜ëŠ” SentenceTransformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.logger.warning("pip install chromadb sentence-transformersë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        self._initialize_chromadb()
    
    def _initialize_chromadb(self):
        """ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ë¡œì»¬ ëª¨ë“œ)
            self.client = chromadb.PersistentClient(
                path="./chromadb_storage",
                settings=Settings(anonymized_telemetry=False)
            )
            
            # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
            collection_name = "warehouse_data"
            try:
                self.collection = self.client.get_collection(collection_name)
                self.logger.info(f"âœ… ê¸°ì¡´ ChromaDB ì»¬ë ‰ì…˜ ë¡œë“œ: {collection_name}")
            except:
                self.collection = self.client.create_collection(collection_name)
                self.logger.info(f"âœ… ìƒˆ ChromaDB ì»¬ë ‰ì…˜ ìƒì„±: {collection_name}")
            
            # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (í•œêµ­ì–´ ì§€ì›, fallback í¬í•¨)
            try:
                self.encoder = SentenceTransformer('jhgan/ko-sroberta-multitask')
                self.logger.info("âœ… í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as korean_model_error:
                self.logger.warning(f"âš ï¸ í•œêµ­ì–´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {korean_model_error}")
                try:
                    # ë‹¤êµ­ì–´ ëª¨ë¸ë¡œ fallback
                    self.encoder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                    self.logger.info("âœ… ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (fallback)")
                except Exception as fallback_error:
                    self.logger.warning(f"âš ï¸ ë‹¤êµ­ì–´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {fallback_error}")
                    # ê°€ì¥ ê¸°ë³¸ì ì¸ ì˜ì–´ ëª¨ë¸ë¡œ fallback
                    self.encoder = SentenceTransformer('all-MiniLM-L6-v2')
                    self.logger.info("âœ… ì˜ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (final fallback)")
            
            self.is_initialized = True
            
        except Exception as e:
            self.logger.error(f"âŒ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.is_initialized = False
    
    async def index_warehouse_data(self, force_rebuild=False):
        """ì°½ê³  ë°ì´í„°ë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¸ë±ì‹±"""
        if not self.is_initialized or not self.data_service:
            self.logger.warning("âš ï¸ VectorDB ë˜ëŠ” DataServiceê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            # ê¸°ì¡´ ë°ì´í„° í™•ì¸
            existing_count = self.collection.count()
            if existing_count > 0 and not force_rebuild:
                self.logger.info(f"âœ… ê¸°ì¡´ ë²¡í„° ë°ì´í„° ì‚¬ìš©: {existing_count}ê°œ ë¬¸ì„œ")
                return True
            
            if force_rebuild and existing_count > 0:
                # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
                self.collection.delete(where={})
                self.logger.info("ğŸ—‘ï¸ ê¸°ì¡´ ë²¡í„° ë°ì´í„° ì‚­ì œ")
            
            documents = []
            metadatas = []
            ids = []
            
            # ì…ê³  ë°ì´í„° ì¸ë±ì‹±
            if self.data_service.inbound_data is not None:
                inbound_docs, inbound_metas, inbound_ids = self._process_inbound_data()
                documents.extend(inbound_docs)
                metadatas.extend(inbound_metas)
                ids.extend(inbound_ids)
            
            # ì¶œê³  ë°ì´í„° ì¸ë±ì‹±
            if self.data_service.outbound_data is not None:
                outbound_docs, outbound_metas, outbound_ids = self._process_outbound_data()
                documents.extend(outbound_docs)
                metadatas.extend(outbound_metas)
                ids.extend(outbound_ids)
            
            # ìƒí’ˆ ë§ˆìŠ¤í„° ë°ì´í„° ì¸ë±ì‹±
            if self.data_service.product_master is not None:
                product_docs, product_metas, product_ids = self._process_product_data()
                documents.extend(product_docs)
                metadatas.extend(product_metas)
                ids.extend(product_ids)
            
            if documents:
                # ì„ë² ë”© ìƒì„±
                self.logger.info(f"ğŸ”„ {len(documents)}ê°œ ë¬¸ì„œ ì„ë² ë”© ìƒì„± ì¤‘...")
                embeddings = self.encoder.encode(documents).tolist()
                
                # ChromaDBì— ì €ì¥
                self.collection.add(
                    documents=documents,
                    metadatas=metadatas,
                    embeddings=embeddings,
                    ids=ids
                )
                
                self.logger.info(f"âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ì‹± ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ")
                return True
            else:
                self.logger.warning("âš ï¸ ì¸ë±ì‹±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ ë²¡í„° ì¸ë±ì‹± ì‹¤íŒ¨: {str(e)}")
            return False
    
    def _process_inbound_data(self):
        """ì…ê³  ë°ì´í„°ë¥¼ ë¬¸ì„œí™”"""
        documents = []
        metadatas = []
        ids = []
        
        df = self.data_service.inbound_data
        for idx, row in df.iterrows():
            # ìì—°ì–´ ë¬¸ì„œ ìƒì„±
            doc = f"""
            ì…ê³  ì •ë³´: {row.get('Supplier', 'ì•Œ ìˆ˜ ì—†ìŒ')} ê³µê¸‰ì—…ì²´ì—ì„œ {row.get('ProductName', 'ì•Œ ìˆ˜ ì—†ìŒ')} ìƒí’ˆì„ 
            {row.get('PalleteQty', 0)}ê°œ íŒŒë ˆíŠ¸ ì…ê³ í–ˆìŠµë‹ˆë‹¤. 
            ë‚ ì§œ: {row.get('Date', 'ì•Œ ìˆ˜ ì—†ìŒ')}, 
            ìƒí’ˆì½”ë“œ: {row.get('ProductCode', 'ì•Œ ìˆ˜ ì—†ìŒ')}, 
            ì…ê³ ìœ„ì¹˜: {row.get('InboundPosition', 'ì•Œ ìˆ˜ ì—†ìŒ')}
            """
            
            # ë©”íƒ€ë°ì´í„° (ì‹¤ì œ ì°¨íŠ¸ì— ì‚¬ìš©ë  ìˆ˜ì¹˜ ë°ì´í„°)
            metadata = {
                "type": "inbound",
                "supplier": str(row.get('Supplier', '')),
                "product_code": str(row.get('ProductCode', '')),
                "product_name": str(row.get('ProductName', '')),
                "quantity": float(row.get('PalleteQty', 0)),
                "date": str(row.get('Date', '')),
                "position": str(row.get('InboundPosition', '')),
                "row_index": int(idx)
            }
            
            documents.append(doc.strip())
            metadatas.append(metadata)
            ids.append(f"inbound_{idx}")
        
        return documents, metadatas, ids
    
    def _process_outbound_data(self):
        """ì¶œê³  ë°ì´í„°ë¥¼ ë¬¸ì„œí™”"""
        documents = []
        metadatas = []
        ids = []
        
        df = self.data_service.outbound_data
        for idx, row in df.iterrows():
            # ìì—°ì–´ ë¬¸ì„œ ìƒì„±
            doc = f"""
            ì¶œê³  ì •ë³´: {row.get('Business name', 'ì•Œ ìˆ˜ ì—†ìŒ')} ê³ ê°ì‚¬ë¡œ {row.get('ProductName', 'ì•Œ ìˆ˜ ì—†ìŒ')} ìƒí’ˆì„ 
            {row.get('PalleteQty', 0)}ê°œ íŒŒë ˆíŠ¸ ì¶œê³ í–ˆìŠµë‹ˆë‹¤. 
            ë‚ ì§œ: {row.get('Date', 'ì•Œ ìˆ˜ ì—†ìŒ')}, 
            ìƒí’ˆì½”ë“œ: {row.get('ProductCode', 'ì•Œ ìˆ˜ ì—†ìŒ')}, 
            ì¶œê³ ìœ„ì¹˜: {row.get('ProductPosition', 'ì•Œ ìˆ˜ ì—†ìŒ')}
            """
            
            # ë©”íƒ€ë°ì´í„°
            metadata = {
                "type": "outbound",
                "business_name": str(row.get('Business name', '')),
                "product_code": str(row.get('ProductCode', '')),
                "product_name": str(row.get('ProductName', '')),
                "quantity": float(row.get('PalleteQty', 0)),
                "date": str(row.get('Date', '')),
                "position": str(row.get('ProductPosition', '')),
                "row_index": int(idx)
            }
            
            documents.append(doc.strip())
            metadatas.append(metadata)
            ids.append(f"outbound_{idx}")
        
        return documents, metadatas, ids
    
    def _process_product_data(self):
        """ìƒí’ˆ ë§ˆìŠ¤í„° ë°ì´í„°ë¥¼ ë¬¸ì„œí™”"""
        documents = []
        metadatas = []
        ids = []
        
        df = self.data_service.product_master
        for idx, row in df.iterrows():
            # ìì—°ì–´ ë¬¸ì„œ ìƒì„±
            doc = f"""
            ìƒí’ˆ ì •ë³´: {row.get('ProductName', 'ì•Œ ìˆ˜ ì—†ìŒ')} (ì½”ë“œ: {row.get('ProductCode', 'ì•Œ ìˆ˜ ì—†ìŒ')})
            í˜„ì¬ ì¬ê³ ëŸ‰: {row.get('í˜„ì¬ê³ ', 0)} {row.get('Unit', 'ê°œ')}, 
            ì €ì¥ìœ„ì¹˜: {row.get('Rack Name', 'ì•Œ ìˆ˜ ì—†ìŒ')} ë™,
            ì‹œì‘ ì¬ê³ ëŸ‰: {row.get('Start Pallete Qty', 0)}
            """
            
            # ë©”íƒ€ë°ì´í„°
            metadata = {
                "type": "product",
                "product_code": str(row.get('ProductCode', '')),
                "product_name": str(row.get('ProductName', '')),
                "current_stock": float(row.get('í˜„ì¬ê³ ', 0)),
                "unit": str(row.get('Unit', '')),
                "rack_name": str(row.get('Rack Name', '')),
                "start_qty": float(row.get('Start Pallete Qty', 0)),
                "row_index": int(idx)
            }
            
            documents.append(doc.strip())
            metadatas.append(metadata)
            ids.append(f"product_{idx}")
        
        return documents, metadatas, ids
    
    async def search_relevant_data(self, query: str, n_results: int = 20) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë°ì´í„° ê²€ìƒ‰"""
        if not self.is_initialized:
            return {"error": "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        try:
            # ì¿¼ë¦¬ ì„ë² ë”©
            query_embedding = self.encoder.encode([query]).tolist()[0]
            
            # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                include=['documents', 'metadatas', 'distances']
            )
            
            if not results['documents'] or not results['documents'][0]:
                return {"error": "ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            # ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬
            documents = results['documents'][0]
            metadatas = results['metadatas'][0]
            distances = results['distances'][0]
            
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì‹¤ì œ ì°¨íŠ¸ ë°ì´í„° ì¶”ì¶œ
            chart_data = self._extract_chart_data_from_metadata(metadatas, query)
            
            return {
                "success": True,
                "query": query,
                "found_documents": len(documents),
                "documents": documents[:5],  # ìƒìœ„ 5ê°œ ë¬¸ì„œë§Œ ë°˜í™˜
                "chart_data": chart_data,
                "metadata_summary": self._summarize_metadata(metadatas)
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return {"error": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
    
    def _extract_chart_data_from_metadata(self, metadatas: List[Dict], query: str) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„°ì—ì„œ ì°¨íŠ¸ ë°ì´í„° ì¶”ì¶œ"""
        try:
            # ì¿¼ë¦¬ ë¶„ì„í•˜ì—¬ ì°¨íŠ¸ íƒ€ì… ì¶”ì •
            query_lower = query.lower()
            
            # ë°ì´í„° íƒ€ì…ë³„ ë¶„ë¥˜
            inbound_data = [m for m in metadatas if m.get('type') == 'inbound']
            outbound_data = [m for m in metadatas if m.get('type') == 'outbound']
            product_data = [m for m in metadatas if m.get('type') == 'product']
            
            chart_data = {}
            
            # ì…ê³  ê´€ë ¨ ì¿¼ë¦¬
            if any(word in query_lower for word in ['ì…ê³ ', 'ê³µê¸‰ì—…ì²´', 'inbound', 'supplier']):
                if inbound_data:
                    chart_data.update(self._process_inbound_chart_data(inbound_data, query_lower))
            
            # ì¶œê³  ê´€ë ¨ ì¿¼ë¦¬
            if any(word in query_lower for word in ['ì¶œê³ ', 'ê³ ê°', 'outbound', 'customer']):
                if outbound_data:
                    chart_data.update(self._process_outbound_chart_data(outbound_data, query_lower))
            
            # ì¬ê³ /ìƒí’ˆ ê´€ë ¨ ì¿¼ë¦¬
            if any(word in query_lower for word in ['ì¬ê³ ', 'ìƒí’ˆ', 'ë™', 'inventory', 'product', 'rack']):
                if product_data:
                    chart_data.update(self._process_product_chart_data(product_data, query_lower))
            
            # ì „ì²´ ë°ì´í„°ê°€ í•„ìš”í•œ ê²½ìš°
            if not chart_data and metadatas:
                chart_data = self._process_general_chart_data(metadatas, query_lower)
            
            return chart_data
            
        except Exception as e:
            self.logger.error(f"âŒ ì°¨íŠ¸ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def _process_inbound_chart_data(self, inbound_data: List[Dict], query: str) -> Dict[str, Any]:
        """ì…ê³  ë°ì´í„°ë¡œ ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
        if 'ê³µê¸‰ì—…ì²´' in query or 'supplier' in query:
            # ê³µê¸‰ì—…ì²´ë³„ ì§‘ê³„
            supplier_counts = {}
            for item in inbound_data:
                supplier = item.get('supplier', 'ì•Œ ìˆ˜ ì—†ìŒ')
                quantity = item.get('quantity', 0)
                supplier_counts[supplier] = supplier_counts.get(supplier, 0) + quantity
            
            return {
                "labels": list(supplier_counts.keys()),
                "data": list(supplier_counts.values()),
                "title": "ê³µê¸‰ì—…ì²´ë³„ ì…ê³ ëŸ‰",
                "type": "inbound_by_supplier"
            }
        
        elif 'ë‚ ì§œ' in query or 'ì¼ë³„' in query or 'daily' in query:
            # ë‚ ì§œë³„ ì§‘ê³„
            date_counts = {}
            for item in inbound_data:
                date = item.get('date', 'ì•Œ ìˆ˜ ì—†ìŒ')
                quantity = item.get('quantity', 0)
                date_counts[date] = date_counts.get(date, 0) + quantity
            
            return {
                "labels": list(date_counts.keys()),
                "data": list(date_counts.values()),
                "title": "ì¼ë³„ ì…ê³ ëŸ‰",
                "type": "inbound_by_date"
            }
        
        return {}
    
    def _process_outbound_chart_data(self, outbound_data: List[Dict], query: str) -> Dict[str, Any]:
        """ì¶œê³  ë°ì´í„°ë¡œ ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
        if 'ê³ ê°' in query or 'customer' in query or 'business' in query:
            # ê³ ê°ì‚¬ë³„ ì§‘ê³„
            business_counts = {}
            for item in outbound_data:
                business = item.get('business_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
                quantity = item.get('quantity', 0)
                business_counts[business] = business_counts.get(business, 0) + quantity
            
            return {
                "labels": list(business_counts.keys()),
                "data": list(business_counts.values()),
                "title": "ê³ ê°ì‚¬ë³„ ì¶œê³ ëŸ‰",
                "type": "outbound_by_business"
            }
        
        elif 'ìƒí’ˆ' in query or 'product' in query:
            # ìƒí’ˆë³„ ì§‘ê³„
            product_counts = {}
            for item in outbound_data:
                product = item.get('product_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
                quantity = item.get('quantity', 0)
                product_counts[product] = product_counts.get(product, 0) + quantity
            
            return {
                "labels": list(product_counts.keys()),
                "data": list(product_counts.values()),
                "title": "ìƒí’ˆë³„ ì¶œê³ ëŸ‰",
                "type": "outbound_by_product"
            }
        
        return {}
    
    def _process_product_chart_data(self, product_data: List[Dict], query: str) -> Dict[str, Any]:
        """ìƒí’ˆ ë°ì´í„°ë¡œ ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
        if 'ë™' in query or 'rack' in query:
            # ë™ë³„ ì§‘ê³„
            rack_counts = {}
            for item in product_data:
                rack = item.get('rack_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
                stock = item.get('current_stock', 0)
                rack_counts[rack] = rack_counts.get(rack, 0) + stock
            
            return {
                "labels": list(rack_counts.keys()),
                "data": list(rack_counts.values()),
                "title": "ë™ë³„ ì¬ê³ ëŸ‰",
                "type": "inventory_by_rack"
            }
        
        return {}
    
    def _process_general_chart_data(self, metadatas: List[Dict], query: str) -> Dict[str, Any]:
        """ì¼ë°˜ì ì¸ ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
        # ë°ì´í„° íƒ€ì…ë³„ ê°œìˆ˜ ì§‘ê³„
        type_counts = {}
        for item in metadatas:
            data_type = item.get('type', 'ì•Œ ìˆ˜ ì—†ìŒ')
            type_counts[data_type] = type_counts.get(data_type, 0) + 1
        
        return {
            "labels": ["ì…ê³ ", "ì¶œê³ ", "ìƒí’ˆ"],
            "data": [
                type_counts.get('inbound', 0),
                type_counts.get('outbound', 0),
                type_counts.get('product', 0)
            ],
            "title": "ë°ì´í„° ìœ í˜•ë³„ ë¶„í¬",
            "type": "general_overview"
        }
    
    def _summarize_metadata(self, metadatas: List[Dict]) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ìš”ì•½"""
        summary = {
            "total_records": len(metadatas),
            "data_types": {},
            "date_range": {"min": None, "max": None},
            "quantity_stats": {"min": 0, "max": 0, "total": 0}
        }
        
        quantities = []
        dates = []
        
        for item in metadatas:
            # ë°ì´í„° íƒ€ì… ì§‘ê³„
            data_type = item.get('type', 'unknown')
            summary["data_types"][data_type] = summary["data_types"].get(data_type, 0) + 1
            
            # ìˆ˜ëŸ‰ í†µê³„
            quantity = item.get('quantity', 0)
            if quantity > 0:
                quantities.append(quantity)
            
            # ë‚ ì§œ ìˆ˜ì§‘
            date_str = item.get('date', '')
            if date_str and date_str != '':
                dates.append(date_str)
        
        # ìˆ˜ëŸ‰ í†µê³„ ê³„ì‚°
        if quantities:
            summary["quantity_stats"] = {
                "min": min(quantities),
                "max": max(quantities),
                "total": sum(quantities),
                "average": sum(quantities) / len(quantities)
            }
        
        # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
        if dates:
            summary["date_range"] = {
                "min": min(dates),
                "max": max(dates),
                "unique_dates": len(set(dates))
            }
        
        return summary
    
    def get_status(self) -> Dict[str, Any]:
        """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ë°˜í™˜"""
        if not self.is_initialized:
            return {
                "status": "not_initialized",
                "message": "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }
        
        try:
            count = self.collection.count()
            return {
                "status": "ready",
                "document_count": count,
                "collection_name": self.collection.name,
                "encoder_model": "jhgan/ko-sroberta-multitask"
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }