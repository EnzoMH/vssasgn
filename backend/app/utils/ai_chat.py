from ..services.ai_service import WarehouseAI
from ..services.data_service import DataService
from ..services.langchain_service import LangChainRAGService
import logging
import asyncio
from typing import Dict, Any, Optional

class WarehouseChatbot:
    def __init__(self, data_service=None, vector_db_service=None, 
                 demand_predictor=None, product_clusterer=None, anomaly_detector=None):
        self.data_service = data_service or DataService()
        self.vector_db_service = vector_db_service
        self.llm_client = WarehouseAI() # WarehouseAI ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        self.logger = logging.getLogger(__name__)
        
        # ğŸš€ LangChain SELF-RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ML ëª¨ë¸ë“¤ í¬í•¨)
        self.langchain_service = LangChainRAGService(
            vector_db_service=self.vector_db_service,
            ai_client=self.llm_client,
            data_service=self.data_service,
            demand_predictor=demand_predictor,
            product_clusterer=product_clusterer,
            anomaly_detector=anomaly_detector
        )
        
        # ì²˜ë¦¬ ì²´ì¸ ì„¤ì • (SELF-RAG ì¶”ê°€)
        self.processing_chains = {
            "direct": self._handle_direct_query,
            "vector_search": self._handle_vector_search_query, 
            "self_rag": self._handle_self_rag_query,  # ìƒˆë¡œ ì¶”ê°€
            "general": self._handle_general_query
        }

    def analyze_intent(self, question: str):
        # ì§ˆë¬¸ì—ì„œ ì˜ë„ ë¶„ì„ (ì˜ˆ: "ì¬ê³ ", "ì¶œê³ ëŸ‰", "ì˜ˆì¸¡")
        if "ì¬ê³ " in question:
            return "inventory"
        elif "ì¶œê³ ëŸ‰" in question:
            return "outbound"
        elif "ì˜ˆìƒ" in question or "ì˜ˆì¸¡" in question:
            return "prediction"
        else:
            return "general"

    async def process_query(self, question: str) -> str:
        """
        ğŸ§  ê°•í™”ëœ AI ì§ˆì˜ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        0. Question Type Analysis (ì§ˆë¬¸ ìœ í˜• ì‚¬ì „ ë¶„ì„)
        1. SELF-RAG (í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ + ìì²´ ê²€ì¦)
        2. Direct Answer (ê°„ë‹¨í•œ ê³„ì‚°)
        3. Specialized Handlers (ì§ˆë¬¸ ìœ í˜•ë³„ ì „ìš© ì²˜ë¦¬)
        4. Fallback Vector Search (ê¸°ì¡´ ë°©ì‹)
        5. General LLM (ìµœí›„ ìˆ˜ë‹¨)
        """
        try:
            self.logger.info(f"ğŸ§  [AI_CHAT] ì§ˆì˜ ì²˜ë¦¬ ì‹œì‘: {question}")
            self.logger.info(f"ğŸ“ [PROMPT_INPUT] ì‚¬ìš©ì ì§ˆë¬¸: '{question}'")
            
            # ğŸ” 0ë‹¨ê³„: ì§ˆë¬¸ ìœ í˜• ì‚¬ì „ ë¶„ì„ (CoT ê¸°ë°˜)
            question_analysis = await self._analyze_question_intent_with_cot(question)
            question_type = question_analysis.get("specific_task", "ê¸°íƒ€")
            needs_vector = question_analysis.get("needs_vector_search", False)
            self.logger.info(f"ğŸ” [AI_ANALYSIS] ì§ˆë¬¸ ìœ í˜•: {question_type}, ë²¡í„° ê²€ìƒ‰ í•„ìš”: {needs_vector}")
            
            # ğŸ¯ 0.1ë‹¨ê³„: CoT ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ ìš°ì„  ì²˜ë¦¬
            if question_type == "ê³„ì‚°" and not needs_vector:
                self.logger.info("ğŸ§® [AI_SPECIALIZED] ê³„ì‚° ì§ˆë¬¸ - ì§ì ‘ ë‹µë³€ ìš°ì„  ì²˜ë¦¬")
                direct_result = await self._handle_direct_query(question)
                if direct_result:
                    self.logger.info(f"âœ… [AI_SUCCESS] ê³„ì‚° ì§ˆë¬¸ ì§ì ‘ ì²˜ë¦¬ ì™„ë£Œ")
                    return direct_result
            
            # ğŸ—ï¸ 0.1.5ë‹¨ê³„: ë™ ê´€ë ¨ ì§ˆë¬¸ ê°•í™” ì²˜ë¦¬ (CoT ê²°ê³¼ì™€ ë¬´ê´€í•˜ê²Œ)
            if any(word in question.lower() for word in ['ë™', 'rack']) and any(char in question.upper() for char in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'):
                self.logger.info("ğŸ—ï¸ [AI_SPECIALIZED] ë™ ê´€ë ¨ ì§ˆë¬¸ - ê°•í™” ì²˜ë¦¬")
                rack_result = await self._handle_rack_specific_query(question)
                if rack_result:
                    self.logger.info(f"âœ… [AI_SUCCESS] ë™ ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ")
                    return rack_result
            
            # ğŸ“… 0.2ë‹¨ê³„: íŠ¹ìˆ˜ ì§ˆë¬¸ ìœ í˜•ë³„ ì¦‰ì‹œ ì²˜ë¦¬
            if question_type == "ë‚ ì§œë¶„ì„":
                self.logger.info("ğŸ“… [AI_SPECIALIZED] ë‚ ì§œ ë¶„ì„ ì „ìš© ì²˜ë¦¬")
                date_result = await self._handle_date_analysis_query(question)
                if date_result:
                    self.logger.info(f"âœ… [AI_SUCCESS] ë‚ ì§œ ë¶„ì„ ì²˜ë¦¬ ì™„ë£Œ")
                    return date_result
            
            elif question_type == "ìƒíƒœë¶„ì„":
                self.logger.info("ğŸ“Š [AI_SPECIALIZED] ìƒíƒœ ë¶„ì„ ì „ìš© ì²˜ë¦¬")
                status_result = await self._handle_status_analysis_query(question)
                if status_result:
                    self.logger.info(f"âœ… [AI_SUCCESS] ìƒíƒœ ë¶„ì„ ì²˜ë¦¬ ì™„ë£Œ")
                    return status_result
            
            elif question_type == "ëª©ë¡ì¡°íšŒ":
                self.logger.info("ğŸ“‹ [AI_SPECIALIZED] ëª©ë¡ ì¡°íšŒ ì „ìš© ì²˜ë¦¬")
                list_result = await self._handle_list_query(question)
                if list_result:
                    self.logger.info(f"âœ… [AI_SUCCESS] ëª©ë¡ ì¡°íšŒ ì²˜ë¦¬ ì™„ë£Œ")
                    return list_result
            
            # ğŸš€ 1ë‹¨ê³„: SELF-RAG ìŠ¤ë§ˆíŠ¸ ì²˜ë¦¬ (í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€)
            self_rag_success = False
            try:
                self.logger.info("ğŸ”¬ [AI_PROCESS] SELF-RAG ìŠ¤ë§ˆíŠ¸ ì²˜ë¦¬ ì‹œë„")
                self_rag_result = await self.langchain_service.smart_process_query(question)
                if self_rag_result and not self_rag_result.startswith("ì˜¤ë¥˜") and "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜" not in self_rag_result:
                    self.logger.info("âœ… [AI_SUCCESS] SELF-RAG ì²˜ë¦¬ ì„±ê³µ")
                    self.logger.info(f"ğŸ¯ [AI_OUTPUT] SELF-RAG ê²°ê³¼: '{self_rag_result[:200]}...'")
                    return self_rag_result
                else:
                    self.logger.warning(f"âš ï¸ [AI_FALLBACK] SELF-RAG ê²°ê³¼ í’ˆì§ˆ ë¶€ì¡±: {self_rag_result[:100] if self_rag_result else 'None'}...")
            except Exception as e:
                self.logger.warning(f"âš ï¸ [AI_ERROR] SELF-RAG ì²˜ë¦¬ ì‹¤íŒ¨, ê°•í™”ëœ fallback ì‚¬ìš©: {e}")
            
            # 2ë‹¨ê³„: ì§ì ‘ ë‹µë³€ ê°€ëŠ¥í•œ ê°„ë‹¨í•œ ì§ˆë¬¸ ì²´í¬
            self.logger.info("ğŸ“Š [AI_PROCESS] ì§ì ‘ ë‹µë³€ ê°€ëŠ¥ì„± ì²´í¬")
            direct_result = await self._handle_direct_query(question)
            if direct_result:
                self.logger.info("ğŸ“Š [AI_SUCCESS] ì§ì ‘ ë‹µë³€ìœ¼ë¡œ ì²˜ë¦¬ ì™„ë£Œ")
                self.logger.info(f"ğŸ¯ [AI_OUTPUT] ì§ì ‘ ë‹µë³€ ê²°ê³¼: '{direct_result[:200]}...'")
                return direct_result
            
            # ğŸ”¥ 3ë‹¨ê³„: ê°•í™”ëœ ë²¡í„° ê²€ìƒ‰ fallback (SELF-RAG ì‹¤íŒ¨ ì‹œ ë” ì ê·¹ì  í™œìš©)
            self.logger.info("ğŸ”„ [AI_PROCESS] ê°•í™”ëœ ë²¡í„° ê²€ìƒ‰ fallback ì‹œì‘")
            enhanced_vector_result = await self._handle_enhanced_vector_fallback(question)
            if enhanced_vector_result:
                self.logger.info(f"ğŸ¯ [AI_OUTPUT] ê°•í™”ëœ ë²¡í„° ê²°ê³¼: '{enhanced_vector_result[:200]}...'")
                return enhanced_vector_result
            
            # 4ë‹¨ê³„: ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰ ë°©ì‹ (ì¶”ê°€ fallback)
            if self._requires_immediate_vector_search(question) or self._is_data_inquiry(question):
                self.logger.info("ğŸ” [AI_PROCESS] ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰ ë°©ì‹ ì‚¬ìš©")
                vector_result = await self._handle_vector_search_query(question)
                if vector_result:
                    self.logger.info(f"ğŸ¯ [AI_OUTPUT] ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: '{vector_result[:200]}...'")
                    return vector_result
            
            # 5ë‹¨ê³„: ìµœí›„ì˜ ì¼ë°˜ LLM ì²˜ë¦¬
            self.logger.info("ğŸ’¬ [AI_PROCESS] ì¼ë°˜ LLM ì²´ì¸ìœ¼ë¡œ ì²˜ë¦¬")
            general_result = await self._handle_general_query(question)
            self.logger.info(f"ğŸ¯ [AI_OUTPUT] ì¼ë°˜ LLM ê²°ê³¼: '{general_result[:200]}...'")
            return general_result
            
        except Exception as e:
            self.logger.error(f"âŒ [AI_ERROR] ì§ˆì˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _requires_immediate_vector_search(self, question: str) -> bool:
        """ì¦‰ì‹œ ë²¡í„° ê²€ìƒ‰ì´ í•„ìš”í•œ íŒ¨í„´ ê°ì§€"""
        question_lower = question.lower()
        
        # íŠ¹ì • ìœ„ì¹˜/ê°ì²´ì˜ ìƒíƒœ/ì •ë³´ë¥¼ ë¬»ëŠ” íŒ¨í„´
        import re
        immediate_patterns = [
            # ë™ ê´€ë ¨
            r"aë™", r"bë™", r"cë™", r"dë™", r"eë™", r"fë™", 
            r"ë™.*ìƒíƒœ", r"ë™.*ì–´ë•Œ", r"ë™.*ì •ë³´", r"ë™.*í˜„í™©",
            r"ë™ì—.*ë­", r"ë™ì—.*ì–´ë–¤", r"ë™ì—.*ë¬´ì—‡",
            
            # ìƒí’ˆ ê´€ë ¨
            r"ì–´ë–¤.*ìƒí’ˆ", r"ë¬´ìŠ¨.*ìƒí’ˆ", r"ë­”.*ìƒí’ˆ",
            r"ìƒí’ˆ.*ëª©ë¡", r"ìƒí’ˆ.*ë¦¬ìŠ¤íŠ¸", r"ìƒí’ˆ.*í˜„í™©",
            
            # ì—…ì²´ ê´€ë ¨  
            r"ì–´ë–¤.*ì—…ì²´", r"ì–´ë–¤.*ê³µê¸‰", r"ì–´ë–¤.*ê³ ê°",
            r"ì£¼ìš”.*ê³µê¸‰", r"ì£¼ìš”.*ì—…ì²´", r"ì£¼ìš”.*ê³ ê°",
            
            # ìƒíƒœ/í˜„í™© ì§ˆë¬¸
            r"ìƒíƒœ.*ì–´ë•Œ", r"í˜„í™©.*ì–´ë•Œ", r"ì–´ë–»ê²Œ.*ë˜", 
            r"ìƒí™©.*ì–´ë•Œ", r"ìƒíƒœ.*ë­", r"í˜„í™©.*ë­"
        ]
        
        for pattern in immediate_patterns:
            if re.search(pattern, question_lower):
                self.logger.info(f"ì¦‰ì‹œ ë²¡í„° ê²€ìƒ‰ íŒ¨í„´ ë§¤ì¹­: {pattern}")
                return True
        return False
    
    def _is_data_inquiry(self, question: str) -> bool:
        """ë°ì´í„° ì¡°íšŒì„± ì§ˆë¬¸ì¸ì§€ íŒë‹¨ (ë‹¨ìˆœ ê³„ì‚° ì œì™¸)"""
        question_lower = question.lower()
        
        # ë°ì´í„° ì¡°íšŒ í‚¤ì›Œë“œ
        inquiry_keywords = [
            "ì–´ë–¤", "ë¬´ì—‡", "ë­", "ëˆ„ê°€", "ì–´ë””", "ì–¸ì œ",
            "ëª©ë¡", "ë¦¬ìŠ¤íŠ¸", "í˜„í™©", "ìƒíƒœ", "ì •ë³´", "ìƒí™©",
            "ë¶„ì„", "í†µê³„", "íŠ¸ë Œë“œ", "íŒ¨í„´", "ë¹„êµ", "ì¡°íšŒ"
        ]
        
        # ë‹¨ìˆœ ê³„ì‚° í‚¤ì›Œë“œ (ë²¡í„° ê²€ìƒ‰ ë¶ˆí•„ìš”)
        import re
        simple_calc_patterns = [
            r"ì´.*ì–¼ë§ˆ", r"ì „ì²´.*ì–¼ë§ˆ", r"í•©ê³„.*ì–¼ë§ˆ",
            r"ì´.*ê°œìˆ˜", r"ì „ì²´.*ê°œìˆ˜", r"í•©ê³„.*ê°œìˆ˜",
            r"ì´.*ì¬ê³ ëŸ‰", r"ì „ì²´.*ì¬ê³ ëŸ‰"
        ]
        
        # ë‹¨ìˆœ ê³„ì‚°ì´ë©´ ë²¡í„° ê²€ìƒ‰ ë¶ˆí•„ìš”
        for pattern in simple_calc_patterns:
            if re.search(pattern, question_lower):
                self.logger.info(f"ë‹¨ìˆœ ê³„ì‚° íŒ¨í„´ìœ¼ë¡œ ë²¡í„° ê²€ìƒ‰ ì œì™¸: {pattern}")
                return False
        
        # ë°ì´í„° ì¡°íšŒì„± ì§ˆë¬¸ì´ë©´ ë²¡í„° ê²€ìƒ‰ í•„ìš”
        has_inquiry = any(keyword in question_lower for keyword in inquiry_keywords)
        if has_inquiry:
            self.logger.info("ë°ì´í„° ì¡°íšŒì„± ì§ˆë¬¸ìœ¼ë¡œ ë²¡í„° ê²€ìƒ‰ í•„ìš”")
        return has_inquiry
    
    async def _needs_vector_search(self, question: str) -> bool:
        """CoTë¥¼ í†µí•œ ì˜ë¯¸ë¡ ì  ë¶„ì„ìœ¼ë¡œ VectorDB ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨"""
        try:
            # 1ë‹¨ê³„: ê¸°ë³¸ í‚¤ì›Œë“œ í•„í„°ë§ (ì„±ëŠ¥ ìµœì í™”)
            basic_keywords = [
                "ì–´ë–¤", "ì–´ë””", "ëˆ„ê°€", "ì–¸ì œ", "ì–¼ë§ˆ", "ëª‡", "ì–¼ë§ˆë‚˜", "ë¬´ì—‡", "ë­", "ë­”ê°€",
                "ë¦¬ìŠ¤íŠ¸", "ëª©ë¡", "í˜„í™©", "ìƒíƒœ", "í†µê³„", "ì¡°íšŒ", "ê²€ìƒ‰", "ë¶„ì„", "ì£¼ìš”",
                "supplier", "ê³µê¸‰ì—…ì²´", "ê³µê¸‰ì‚¬", "ê³ ê°ì‚¬", "ì—…ì²´", "íšŒì‚¬", "ê¸°ì—…", 
                "product", "ìƒí’ˆ", "ì œí’ˆ", "í’ˆëª©", "ë™", "rack", "ì¬ê³ ", "ìˆ˜ëŸ‰", "aë™", "bë™"
            ]
            
            question_lower = question.lower()
            has_basic_keywords = any(keyword in question_lower for keyword in basic_keywords)
            
            if not has_basic_keywords:
                return False
            
            # 2ë‹¨ê³„: ê°„ë‹¨í•œ íŒ¨í„´ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§
            simple_calc_patterns = ["ì´ ì¬ê³ ëŸ‰", "ì´ì¬ê³ ", "ì „ì²´ ì¬ê³ ëŸ‰", "í˜„ì¬ ì¬ê³ ëŸ‰ì´ ì–¼ë§ˆ"]
            if any(pattern in question_lower for pattern in simple_calc_patterns):
                self.logger.info("ì‚¬ì „ í•„í„°ë§: ê°„ë‹¨í•œ ê³„ì‚° ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨")
                return False
            
            # ë²¡í„° ê²€ìƒ‰ í•„ìˆ˜ íŒ¨í„´
            vector_required_patterns = ["ì–´ë–¤ ìƒí’ˆ", "ì–´ë–¤ ì—…ì²´", "ì£¼ìš” ê³µê¸‰", "ì£¼ìš” ìƒí’ˆ", "aë™", "bë™", "ë™ì—"]
            if any(pattern in question_lower for pattern in vector_required_patterns):
                self.logger.info("ì‚¬ì „ í•„í„°ë§: ë²¡í„° ê²€ìƒ‰ í•„ìˆ˜ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨")
                return True
            
            # 3ë‹¨ê³„: CoT ê¸°ë°˜ ì˜ë¯¸ë¡ ì  ë¶„ì„ (ë³µì¡í•œ ì¼€ì´ìŠ¤ë§Œ)
            cot_analysis = await self._analyze_question_intent_with_cot(question)
            
            # 4ë‹¨ê³„: CoT ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… íŒë‹¨
            needs_vector = cot_analysis.get("needs_vector_search", False)
            confidence = cot_analysis.get("confidence", 0.5)
            reasoning = cot_analysis.get("reasoning", "")
            
            self.logger.info(f"CoT ë¶„ì„ ê²°ê³¼: needs_vector={needs_vector}, confidence={confidence}, reasoning={reasoning[:100]}...")
            
            return needs_vector
            
        except Exception as e:
            self.logger.warning(f"CoT ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ fallback: {e}")
            # fallback: ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­
            basic_vector_keywords = [
                "ë¶„ì„", "íŠ¸ë Œë“œ", "íŒ¨í„´", "ì˜ˆì¸¡", "supplier", "ê³µê¸‰ì—…ì²´", "ê³ ê°ì‚¬",
                "ìƒí’ˆ", "ì œí’ˆ", "ë™", "ì¬ê³ ", "ì–´ë–¤", "ì–´ë””", "ëˆ„ê°€", "ì–¼ë§ˆ"
            ]
            return any(keyword in question_lower for keyword in basic_vector_keywords)
    
    async def _analyze_question_intent_with_cot(self, question: str) -> Dict[str, Any]:
        """Chain of Thoughtë¥¼ í†µí•œ ì§ˆë¬¸ ì˜ë„ ë¶„ì„"""
        try:
            if not self.llm_client:
                self.logger.warning("ğŸ”´ [COT_ERROR] LLM í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ")
                return {"needs_vector_search": False, "reasoning": "LLM í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ"}
            
            self.logger.info(f"ğŸ§  [COT_START] ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì‹œì‘: '{question}'")
            
            cot_prompt = f"""
ë‹¹ì‹ ì€ ì°½ê³  ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ì§ˆì˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì„ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ì²˜ë¦¬ ë°©ì‹ì´ í•„ìš”í•œì§€ ì •í™•íˆ íŒë‹¨í•˜ì„¸ìš”.

**ì§ˆë¬¸:** "{question}"

**ğŸ” í•µì‹¬ ë¶„ì„ ë‹¨ê³„:**
1. **ì§ˆë¬¸ ì˜ë„ íŒŒì•…**: ì´ ì§ˆë¬¸ì´ ì •ë§ë¡œ ì›í•˜ëŠ” ê²ƒì€?
   - "ì–¸ì œ" â†’ ë‚ ì§œ/ì‹œê°„ ì •ë³´ í•„ìš”
   - "ì–´ë–¤" â†’ ëª©ë¡/ìƒì„¸ ì •ë³´ í•„ìš”  
   - "ì–¼ë§ˆ" â†’ ìˆ˜ëŸ‰/ê¸ˆì•¡ ì •ë³´ í•„ìš”
   - "ë¶€ì¡±í•œ" â†’ ì„ê³„ê°’ ê¸°ë°˜ ë¶„ì„ í•„ìš”

2. **ë°ì´í„° ì²˜ë¦¬ ë°©ì‹**: 
   - "ì–¸ì œê°€ ì œì¼ ë†’ì•˜ë˜" â†’ ë‚ ì§œë³„ ë¶„ì„ + ìµœëŒ“ê°’ ê²€ìƒ‰ â†’ ë²¡í„° ê²€ìƒ‰ í•„ìš”
   - "ë¶€ì¡±í•œ ì œí’ˆ" â†’ ì¬ê³  ë¶„ì„ + ì„ê³„ê°’ ë¹„êµ â†’ ë²¡í„° ê²€ìƒ‰ í•„ìš”
   - "ì´ ì¬ê³ ëŸ‰" â†’ ë‹¨ìˆœ í•©ê³„ â†’ ì§ì ‘ ê³„ì‚°
   - "ë™ ìƒíƒœ" â†’ íŠ¹ì • ìœ„ì¹˜ ì •ë³´ â†’ ë²¡í„° ê²€ìƒ‰ í•„ìš”

**ğŸ¯ ê°•í™”ëœ íŒë‹¨ ê¸°ì¤€:**
- **ì§ì ‘ ê³„ì‚°**: "ì´/ì „ì²´ + ìˆ˜ëŸ‰" (ex: ì´ ì¬ê³ ëŸ‰, ì „ì²´ ì…ê³ ëŸ‰)
- **ë‚ ì§œ ë¶„ì„**: "ì–¸ì œ", "ê°€ì¥ ë†’ì•˜ë˜ ë‚ ", "ìµœëŒ€/ìµœì†Œì¸ ë‚ " â†’ ë°˜ë“œì‹œ ë²¡í„° ê²€ìƒ‰
- **ëª©ë¡ ì¡°íšŒ**: "ì–´ë–¤", "ì–´ëŠ", "ë¬´ìŠ¨", "ë¦¬ìŠ¤íŠ¸", "ëª©ë¡" â†’ ë°˜ë“œì‹œ ë²¡í„° ê²€ìƒ‰  
- **ìƒíƒœ ë¶„ì„**: "ë¶€ì¡±í•œ", "ìœ„í—˜í•œ", "ë§ì€", "ì ì€" â†’ ë°˜ë“œì‹œ ë²¡í„° ê²€ìƒ‰
- **ìœ„ì¹˜ ì¡°íšŒ**: "Aë™", "Bë™", "Cë™", "ë™ ìƒíƒœ" â†’ ë°˜ë“œì‹œ ë²¡í„° ê²€ìƒ‰
- **ì¼ë°˜ ì§ˆë¬¸**: ê°œë…, ì‚¬ìš©ë²•, ì‹œìŠ¤í…œ ì™¸ë¶€ ì§ˆë¬¸ â†’ ì¼ë°˜ LLM

**ğŸš¨ í•„ìˆ˜ ë²¡í„° ê²€ìƒ‰ íŒ¨í„´:**
- "ì…ê³ ëŸ‰ì´ ì œì¼ ë†’ì•˜ë˜ ë‚ " â†’ ë‚ ì§œë³„ ë¶„ì„ í•„ìš” (ë²¡í„° ê²€ìƒ‰)
- "ì¬ê³ ê°€ ë¶€ì¡±í•œ ì œí’ˆ" â†’ ì„ê³„ê°’ ë¶„ì„ í•„ìš” (ë²¡í„° ê²€ìƒ‰)
- "Cë™ì˜ ìƒíƒœ" â†’ ìœ„ì¹˜ íŠ¹ì • ì¡°íšŒ (ë²¡í„° ê²€ìƒ‰)
- "ì–´ë–¤ ìƒí’ˆë“¤" â†’ ëª©ë¡ ì¡°íšŒ (ë²¡í„° ê²€ìƒ‰)

**ì‘ë‹µ í˜•ì‹ (JSON):**
{{
    "question_type": "date_analysis|list_query|status_analysis|calculation|explanation|other",
    "data_scope": "simple|complex|none",
    "reasoning": "ì§ˆë¬¸ ì˜ë„ì™€ í•„ìš”í•œ ì²˜ë¦¬ ë°©ì‹ì— ëŒ€í•œ êµ¬ì²´ì  ë¶„ì„",
    "needs_vector_search": true|false,
    "specific_task": "ë‚ ì§œë¶„ì„|ëª©ë¡ì¡°íšŒ|ìƒíƒœë¶„ì„|ê³„ì‚°|ì„¤ëª…|ê¸°íƒ€",
    "confidence": 0.0-1.0
}}
"""
            
            self.logger.info(f"ğŸ“ [COT_PROMPT] ìƒì„±ëœ CoT í”„ë¡¬í”„íŠ¸:\n{cot_prompt}")
            
            # ê°„ë‹¨í•œ LLM í˜¸ì¶œë¡œ CoT ë¶„ì„ ìˆ˜í–‰ (CoT í”Œë˜ê·¸ ì „ë‹¬)
            self.logger.info("ğŸ”„ [COT_PROCESS] LLMì— CoT ë¶„ì„ ìš”ì²­")
            response = await self.llm_client.answer_simple_query(cot_prompt, {"cot_analysis": True})
            self.logger.info(f"ğŸ¯ [COT_RESPONSE] LLM ì‘ë‹µ: '{response[:200]}...'")
            
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            import json
            try:
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    json_str = response[json_start:json_end]
                    self.logger.info(f"ğŸ“‹ [COT_PARSING] ì¶”ì¶œëœ JSON: {json_str}")
                    analysis = json.loads(json_str)
                    
                    self.logger.info(f"âœ… [COT_SUCCESS] CoT ë¶„ì„ ì™„ë£Œ: {analysis.get('reasoning', '')}")
                    self.logger.info(f"ğŸ” [COT_RESULT] ë²¡í„°ê²€ìƒ‰ í•„ìš”: {analysis.get('needs_vector_search', False)}, ì‹ ë¢°ë„: {analysis.get('confidence', 0)}")
                    return analysis
                else:
                    raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    
            except (json.JSONDecodeError, ValueError) as e:
                self.logger.warning(f"âš ï¸ [COT_FALLBACK] CoT JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                # ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ fallback
                fallback_result = self._fallback_intent_analysis(question, response)
                self.logger.info(f"ğŸ”„ [COT_FALLBACK] Fallback ë¶„ì„ ê²°ê³¼: {fallback_result}")
                return fallback_result
                
        except Exception as e:
            self.logger.warning(f"CoT ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"needs_vector_search": False, "reasoning": f"ë¶„ì„ ì‹¤íŒ¨: {e}"}
    
    def _fallback_intent_analysis(self, question: str, llm_response: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µ ê¸°ë°˜ fallback ì˜ë„ ë¶„ì„"""
        response_lower = llm_response.lower()
        
        # LLM ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ê°ì§€
        vector_indicators = [
            "ë²¡í„° ê²€ìƒ‰", "vector", "ë³µí•©", "ê²€ìƒ‰", "ì¡°íšŒ", "ë¶„ì„", 
            "ë°ì´í„°", "ëª©ë¡", "ë¹„êµ", "ìƒìœ„", "í•˜ìœ„"
        ]
        
        direct_indicators = [
            "ì§ì ‘", "ê³„ì‚°", "ë‹¨ìˆœ", "í•©ê³„", "ì´", "ê°„ë‹¨"
        ]
        
        has_vector_indicators = any(indicator in response_lower for indicator in vector_indicators)
        has_direct_indicators = any(indicator in response_lower for indicator in direct_indicators)
        
        if has_vector_indicators and not has_direct_indicators:
            return {
                "needs_vector_search": True,
                "reasoning": "LLM ì‘ë‹µì—ì„œ ë³µí•© ê²€ìƒ‰ í•„ìš”ì„± ê°ì§€",
                "confidence": 0.7
            }
        elif has_direct_indicators:
            return {
                "needs_vector_search": False,
                "reasoning": "LLM ì‘ë‹µì—ì„œ ì§ì ‘ ê³„ì‚° ê°€ëŠ¥ì„± ê°ì§€",
                "confidence": 0.8
            }
        else:
            # ì§ˆë¬¸ ìì²´ì—ì„œ ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­
            question_lower = question.lower()
            complex_patterns = ["ì–´ë–¤", "ì–´ëŠ", "ëˆ„ê°€", "ë­ê°€", "ë¬´ì—‡", "ë¦¬ìŠ¤íŠ¸", "ëª©ë¡", "ìƒìœ„", "í•˜ìœ„"]
            
            if any(pattern in question_lower for pattern in complex_patterns):
                return {
                    "needs_vector_search": True,
                    "reasoning": "ì§ˆë¬¸ì—ì„œ ë³µí•© ì¡°íšŒ íŒ¨í„´ ê°ì§€",
                    "confidence": 0.6
                }
            else:
                return {
                    "needs_vector_search": False,
                    "reasoning": "ë‹¨ìˆœ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨",
                    "confidence": 0.5
                }

    async def _handle_direct_query(self, question: str) -> Optional[str]:
        """ì§ì ‘ ê³„ì‚°ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ê°„ë‹¨í•œ ì§ˆë¬¸ ì²˜ë¦¬"""
        return self._try_direct_answer(question)
    
    async def _handle_vector_search_query(self, question: str) -> Optional[str]:
        """ê°•í™”ëœ VectorDB ê²€ìƒ‰ - fallback ë° ìƒì„¸ ì‘ë‹µ í¬í•¨"""
        if not (self.vector_db_service and self.vector_db_service.is_initialized):
            self.logger.warning("VectorDB ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ, fallback ì‹¤í–‰")
            return await self._fallback_data_query(question)
            
        try:
            self.logger.info(f"ğŸ” VectorDB ê²€ìƒ‰ ì‹œì‘: {question} (ì´ 2,900ê°œ ë¬¸ì„œ ëŒ€ìƒ)")
            search_result = await self.vector_db_service.search_relevant_data(
                query=question,
                n_results=25  # 2,900ê°œ ë¬¸ì„œì—ì„œ ë” ë§ì€ ê²°ê³¼ ê²€ìƒ‰
            )
            
            if not search_result.get("success"):
                self.logger.warning("âš ï¸ VectorDB ê²€ìƒ‰ ì‹¤íŒ¨, fallback ì‹¤í–‰")
                return await self._fallback_data_query(question)
            
            # ê²€ìƒ‰ ê²°ê³¼ ìƒíƒœ ë¡œê¹…
            found_docs = search_result.get('found_documents', 0)
            if found_docs > 0:
                self.logger.info(f"âœ… {found_docs}ê°œ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬")
            else:
                self.logger.warning("âš ï¸ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨, fallback ì‹¤í–‰")
                return await self._fallback_data_query(question)
                
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìƒì„¸ ì‘ë‹µ ìƒì„±
            return await self._generate_detailed_response(search_result, question)
            
        except Exception as e:
            self.logger.error(f"VectorDB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return await self._fallback_data_query(question)
    
    async def _fallback_data_query(self, question: str) -> str:
        """VectorDB ì‹¤íŒ¨ ì‹œ ì§ì ‘ ë°ì´í„° ì¡°íšŒ"""
        question_lower = question.lower()
        
        try:
            # ğŸ¢ ê°œì„ ëœ ë™ë³„ ìƒíƒœ ë¬¸ì˜ ì²˜ë¦¬ (ëª¨ë“  ë™ ì§€ì›)
            rack_patterns = ["aë™", "bë™", "cë™", "dë™", "eë™", "fë™", "gë™", "hë™", "ië™", "jë™", "kë™", "lë™", "më™", "në™", "oë™", "pë™", "që™", "rë™", "së™", "të™", "uë™", "vë™", "wë™", "xë™", "yë™", "zë™"]
            
            for rack_pattern in rack_patterns:
                if rack_pattern in question_lower and ("ìƒíƒœ" in question_lower or "ì–´ë•Œ" in question_lower or "ì–´ë–¤" in question_lower):
                    rack_letter = rack_pattern[0].upper()  # A, B, C, ... ì¶”ì¶œ
                    rack_data = self._get_rack_specific_data(rack_letter)
                    
                    if rack_data:
                        rack_name = rack_data.get('rack_name', f'{rack_letter}ë™')
                        current_stock = rack_data.get('current_stock', 0)
                        utilization_rate = rack_data.get('utilization_rate', 0)
                        products = rack_data.get('products', ['ì •ë³´ ì—†ìŒ'])
                        product_count = rack_data.get('product_count', 0)
                        status = rack_data.get('status', 'âš ï¸ ì•Œ ìˆ˜ ì—†ìŒ')
                        found_method = rack_data.get('found_method', 'legacy')
                        
                        # ğŸ¯ ìƒìœ„ 3ê°œ ìƒí’ˆëª… í‘œì‹œ
                        top_products = ', '.join(products[:3]) if len(products) > 0 else 'ì •ë³´ ì—†ìŒ'
                        if len(products) > 3:
                            top_products += f" ì™¸ {len(products) - 3}ê°œ"
                        
                        data_quality = "âœ… í†µí•© ê³„ì‚° ê¸°ë°˜" if found_method == 'unified_calculation' else "âš ï¸ ë ˆê±°ì‹œ ë°©ì‹"
                        
                        return f"""ğŸ¢ **{rack_name} ìƒíƒœ ì •ë³´:** {data_quality}

ğŸ“Š **ì¬ê³  í˜„í™©:** {current_stock:,}ê°œ
ğŸ“ˆ **í™œìš©ë¥ :** {utilization_rate:.1f}%
ğŸ“¦ **ì €ì¥ ìƒí’ˆ:** {top_products}
ğŸ“‹ **ìƒí’ˆ ì¢…ë¥˜:** {product_count}ê°œ
âš ï¸ **ìƒíƒœ:** {status}

ğŸ’¡ **ë°ì´í„° ì¼ê´€ì„±:** ëª¨ë“  ì‹œìŠ¤í…œì—ì„œ ë™ì¼í•œ ìˆ˜ì¹˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤."""
                    
                    else:
                        return f"""âŒ **{rack_letter}ë™ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.**

ğŸ” **í™•ì¸ëœ ë¬¸ì œ:**
- í•´ë‹¹ ë™ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜
- ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ

ğŸ’¡ **í•´ê²° ë°©ë²•:**
1. ë™ ì´ë¦„ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš” (A~Z)
2. 'ì „ì²´ ë™ í˜„í™©'ì„ ë¨¼ì € í™•ì¸í•´ë³´ì„¸ìš”
3. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”"""
            
            # ì¼ë°˜ ë™ ê´€ë ¨ ì§ˆë¬¸
            if any(word in question_lower for word in ['ë™', 'rack']) and any(word in question_lower for word in ['ìƒíƒœ', 'ì–´ë•Œ', 'í˜„í™©', 'ì •ë³´']):
                all_racks_data = self._get_all_racks_summary()
                return f"""ğŸ¢ **ì „ì²´ ë™ ìƒíƒœ í˜„í™©:**

{all_racks_data}

ğŸ’¡ íŠ¹ì • ë™ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì›í•˜ì‹œë©´ "Aë™ ìƒíƒœëŠ” ì–´ë•Œ?" í˜•ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."""
            
            # ìƒí’ˆ ê´€ë ¨ ì§ˆë¬¸
            if any(word in question_lower for word in ['ìƒí’ˆ', 'ì œí’ˆ']) and any(word in question_lower for word in ['ì–´ë–¤', 'ë­', 'ëª©ë¡']):
                return """ğŸ“¦ **ì£¼ìš” ìƒí’ˆ ì •ë³´:**

í˜„ì¬ ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œì´ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì •ë³´ë§Œ ì œê³µë©ë‹ˆë‹¤.

ğŸ”§ **ì‹œìŠ¤í…œ ìƒíƒœ:** ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì‹œì‘ í•„ìš”
ğŸ’¡ **ê¶Œì¥ ì‚¬í•­:** ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì—¬ ë²¡í„° DB ì„œë¹„ìŠ¤ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.

ğŸ“ **ëŒ€ì•ˆ:** ëŒ€ì‹œë³´ë“œì˜ 'ìƒí’ˆë³„ ì¬ê³  í˜„í™©' ì°¨íŠ¸ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”."""
            
        except Exception as e:
            self.logger.error(f"Fallback ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        
        return """âŒ **ì‹œìŠ¤í…œ ì¼ì‹œ ì˜¤ë¥˜**

í˜„ì¬ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ğŸ”§ **ê°€ëŠ¥í•œ ì›ì¸:**
- ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜
- ë°ì´í„° ì„œë¹„ìŠ¤ ì¼ì‹œ ì¤‘ë‹¨

ğŸ’¡ **í•´ê²° ë°©ì•ˆ:**
1. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”
2. ëŒ€ì‹œë³´ë“œ ì°¨íŠ¸ë¥¼ í†µí•´ ê¸°ë³¸ ì •ë³´ í™•ì¸
3. ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜

ğŸ“ **ë¬¸ì˜:** /api/vector-db/statusë¡œ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
    
    def _get_rack_specific_data(self, rack_name: str) -> dict:
        """íŠ¹ì • ë™ì˜ ë°ì´í„° ì¡°íšŒ - í†µí•© ê³„ì‚° ê¸°ë°˜ìœ¼ë¡œ ê°œì„ """
        try:
            # ğŸ”„ í†µí•© ê³„ì‚° ë©”ì„œë“œ ì‚¬ìš©
            unified_stats = self.data_service.get_unified_inventory_stats()
            
            if "error" in unified_stats:
                self.logger.error(f"âŒ í†µí•© ê³„ì‚° ì‹¤íŒ¨: {unified_stats['error']}")
                return {}
            
            rack_distribution = unified_stats.get("rack_distribution", {})
            rack_column = unified_stats.get("rack_column_used")
            
            self.logger.info(f"ğŸ” [RACK_SEARCH] ì°¾ëŠ” ë™: {rack_name}, ì‚¬ìš© ì»¬ëŸ¼: {rack_column}")
            self.logger.info(f"ğŸ” [RACK_SEARCH] ì‚¬ìš© ê°€ëŠ¥í•œ ë™ë“¤: {list(rack_distribution.keys())}")
            
            # ğŸ¯ ê°œì„ ëœ ë™ ì´ë¦„ ë§¤ì¹­ (ë‹¤ì–‘í•œ í˜•íƒœ ì§€ì›)
            target_rack = None
            rack_variations = [
                rack_name.upper(),          # A, B, C
                f"{rack_name.upper()}ë™",    # Aë™, Bë™, Cë™
                f"{rack_name.upper()}-RACK", # A-RACK, B-RACK
                rack_name.lower(),          # a, b, c
                f"Rack {rack_name.upper()}", # Rack A, Rack B
                f"{rack_name.upper()}Rack",  # ARack, BRack
            ]
            
            # ì •í™•í•œ ë§¤ì¹­ ìš°ì„  ì‹œë„
            for variation in rack_variations:
                for available_rack in rack_distribution.keys():
                    if variation == available_rack or variation in available_rack:
                        target_rack = available_rack
                        self.logger.info(f"âœ… [RACK_FOUND] ë§¤ì¹­ ì„±ê³µ: {rack_name} â†’ {target_rack}")
                        break
                if target_rack:
                    break
            
            # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ì •í™•í•œ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ)
            if not target_rack:
                for available_rack in rack_distribution.keys():
                    if rack_name.upper() in available_rack.upper():
                        target_rack = available_rack
                        self.logger.info(f"ğŸ” [RACK_PARTIAL] ë¶€ë¶„ ë§¤ì¹­: {rack_name} â†’ {target_rack}")
                        break
            
            if not target_rack:
                self.logger.warning(f"âŒ [RACK_NOT_FOUND] ë™ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {rack_name}")
                self.logger.warning(f"ğŸ“‹ [AVAILABLE_RACKS] ì‚¬ìš© ê°€ëŠ¥í•œ ë™ë“¤: {list(rack_distribution.keys())}")
                return {}
            
            # ğŸ“Š ë™ë³„ ìƒì„¸ ë°ì´í„° ê³„ì‚°
            current_stock = int(rack_distribution[target_rack])
            
            # ğŸ“ˆ ì‹¤ì œ ìƒí’ˆ ì •ë³´ ì¡°íšŒ (ì§ì ‘ DataFrame ì ‘ê·¼)
            if self.data_service.product_master is not None and rack_column:
                import pandas as pd
                rack_products = self.data_service.product_master[
                    self.data_service.product_master[rack_column] == target_rack
                ]
                
                product_count = len(rack_products)
                product_names = rack_products['ProductName'].unique().tolist() if 'ProductName' in rack_products.columns else []
                
                # ğŸ“¦ ì œí’ˆëª… ì •ë¦¬ (ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬)
                valid_products = [name for name in product_names if pd.notna(name) and str(name).strip()]
                if not valid_products:
                    valid_products = [f"ì œí’ˆ-{i+1}" for i in range(product_count)]  # ê¸°ë³¸ ì œí’ˆëª… ìƒì„±
                
            else:
                product_count = max(1, current_stock // 25)  # ì¶”ì • ì œí’ˆ ìˆ˜
                valid_products = [f"ì œí’ˆ-{i+1}" for i in range(product_count)]
            
            # ğŸ—ï¸ ìš©ëŸ‰ ë° í™œìš©ë¥  ê³„ì‚°
            avg_capacity_per_rack = 50  # ë™ë‹¹ í‰ê·  50ê°œ ìš©ëŸ‰
            max_capacity = avg_capacity_per_rack
            utilization_rate = (current_stock / max_capacity) * 100 if max_capacity > 0 else 0
            
            # ğŸ“‹ ìƒíƒœ ë¶„ì„
            status = "âœ… ì •ìƒ" if utilization_rate < 80 else "âš ï¸ ì£¼ì˜" if utilization_rate < 95 else "ğŸš¨ í¬í™”"
            
            result = {
                'rack_name': target_rack,
                'current_stock': current_stock,
                'max_capacity': max_capacity,
                'utilization_rate': utilization_rate,
                'products': valid_products,
                'product_count': product_count,
                'rack_column_used': rack_column,
                'status': status,
                'is_estimated': False,  # í†µí•© ê³„ì‚° ê¸°ë°˜ì´ë¯€ë¡œ ì¶”ì •ê°’ ì•„ë‹˜
                'found_method': 'unified_calculation'
            }
            
            self.logger.info(f"ğŸ“Š [RACK_RESULT] {target_rack}: {current_stock}ê°œ, {utilization_rate:.1f}%, {product_count}ê°œ ì œí’ˆ")
            return result
                    
        except Exception as e:
            self.logger.error(f"âŒ ë™ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {}
    
    def _get_all_racks_summary(self) -> str:
        """ì „ì²´ ë™ ìš”ì•½ ì •ë³´ - í†µí•© ê³„ì‚° ê¸°ë°˜ìœ¼ë¡œ ê°œì„ """
        try:
            # ğŸ”„ í†µí•© ê³„ì‚° ë©”ì„œë“œ ì‚¬ìš©
            unified_stats = self.data_service.get_unified_inventory_stats()
            
            if "error" in unified_stats:
                self.logger.error(f"âŒ í†µí•© ê³„ì‚° ì‹¤íŒ¨: {unified_stats['error']}")
                return "ğŸ“Š í˜„ì¬ ë™ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            rack_distribution = unified_stats.get("rack_distribution", {})
            
            if not rack_distribution:
                return "âŒ ë™ ë¶„í¬ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ğŸ“Š ë™ë³„ ì •ë³´ë¥¼ ì¬ê³ ëŸ‰ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_racks = sorted(rack_distribution.items(), key=lambda x: x[1], reverse=True)
            
            summary_lines = []
            total_racks = len(sorted_racks)
            total_inventory = sum(rack_distribution.values())
            
            # ğŸ” ìƒìœ„ 10ê°œ ë™ ì •ë³´ í‘œì‹œ
            for i, (rack, qty) in enumerate(sorted_racks[:10]):
                avg_capacity_per_rack = 50  # ë™ë‹¹ í‰ê·  50ê°œ ìš©ëŸ‰
                utilization = (qty / avg_capacity_per_rack) * 100 if avg_capacity_per_rack > 0 else 0
                
                # ğŸ“Š ìƒíƒœ ì•„ì´ì½˜
                status_icon = "âœ…" if utilization < 80 else "âš ï¸" if utilization < 95 else "ğŸš¨"
                
                # ğŸ“ˆ ë°±ë¶„ìœ¨ ê³„ì‚° (ì „ì²´ ì¬ê³  ëŒ€ë¹„)
                percentage = (qty / total_inventory * 100) if total_inventory > 0 else 0
                
                summary_lines.append(f"{status_icon} **{rack}:** {int(qty):,}ê°œ ({utilization:.1f}%, ì „ì²´ì˜ {percentage:.1f}%)")
            
            # ğŸ“‹ ìš”ì•½ ì •ë³´ ì¶”ê°€
            if total_racks > 10:
                summary_lines.append(f"\nğŸ“Š **ì „ì²´ ìš”ì•½:** {total_racks}ê°œ ë™ ì¤‘ ìƒìœ„ 10ê°œ í‘œì‹œ")
            
            summary_lines.append(f"ğŸ“¦ **ì´ ì¬ê³ ëŸ‰:** {int(total_inventory):,}ê°œ (í†µí•© ê³„ì‚°)")
            summary_lines.append(f"ğŸ¢ **í™œì„± ë™ ìˆ˜:** {total_racks}ê°œ")
            
            return "\n".join(summary_lines)
            
        except Exception as e:
            self.logger.error(f"âŒ ì „ì²´ ë™ ìš”ì•½ ì˜¤ë¥˜: {e}")
            return "ğŸ“Š í˜„ì¬ ë™ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    async def _generate_detailed_response(self, search_result: dict, question: str) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸ ì‘ë‹µ ìƒì„±"""
        try:
            # Vector ê²€ìƒ‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
            structured_context = self._vectordb_to_prompt(search_result, question)
            
            # ìµœì í™”ëœ VectorDB ì „ìš© LLM í˜¸ì¶œ
            response = await self.llm_client.answer_with_vector_context(
                question, structured_context
            )
            
            # ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜ ì •ë³´ëŠ” ë” ì´ìƒ í‘œì‹œí•˜ì§€ ì•ŠìŒ (ì‚¬ìš©ì ìš”ì²­)
            
            self.logger.info("VectorDB ê²€ìƒ‰ ìƒì„¸ ì‘ë‹µ ìƒì„± ì™„ë£Œ")
            return response
            
        except Exception as e:
            self.logger.error(f"ìƒì„¸ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return await self._fallback_data_query(question)
    
    async def _handle_general_query(self, question: str) -> str:
        """ì¼ë°˜ì ì¸ ì§ˆë¬¸ì„ ê¸°ë³¸ ë°ì´í„°ë¡œ ì²˜ë¦¬"""
        intent = self.analyze_intent(question)
        context_data = self.data_service.get_relevant_data(intent)
        
        # ê°„ë‹¨í•œ LLM í˜¸ì¶œ (VectorDB ì—†ì´)
        return await self.llm_client.answer_simple_query(question, context_data)
    
    def _vectordb_to_prompt(self, search_result: Dict, question: str) -> str:
        """VectorDB ê²€ìƒ‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜"""
        self.logger.info(f"ğŸ”„ [PROMPT_BUILD] VectorDB â†’ í”„ë¡¬í”„íŠ¸ ë³€í™˜ ì‹œì‘")
        
        documents = search_result.get('documents', [])
        chart_data = search_result.get('chart_data', {})
        metadata_summary = search_result.get('metadata_summary', {})
        
        self.logger.info(f"ğŸ“Š [PROMPT_DATA] ë¬¸ì„œ: {len(documents)}ê°œ, ì°¨íŠ¸ë°ì´í„°: {bool(chart_data)}, ë©”íƒ€ë°ì´í„°: {bool(metadata_summary)}")
        
        prompt_parts = [
            f"ì§ˆë¬¸: {question}",
            "",
            "== ì‹¤ì œ ì°½ê³  ë°ì´í„° ê²€ìƒ‰ ê²°ê³¼ ==",
            f"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {search_result.get('found_documents', 0)}ê°œ",
            ""
        ]
        
        # ë©”íƒ€ë°ì´í„° ìš”ì•½ ì •ë³´ ì¶”ê°€ (ë” êµ¬ì²´ì )
        if metadata_summary:
            prompt_parts.extend([
                "== ë°ì´í„° ìš”ì•½ ì •ë³´ ==",
                f"â€¢ ì´ ë ˆì½”ë“œ: {metadata_summary.get('total_records', 0)}ê°œ",
                f"â€¢ ë°ì´í„° ìœ í˜•: {metadata_summary.get('data_types', {})}",
                f"â€¢ ë‚ ì§œ ë²”ìœ„: {metadata_summary.get('date_range', {})}",
                f"â€¢ ìˆ˜ëŸ‰ í†µê³„: {metadata_summary.get('quantity_stats', {})}",
                ""
            ])
        
        # ë¬¸ì„œ ì •ë³´ ì¶”ê°€ (ìƒìœ„ 3ê°œ)
        if documents:
            prompt_parts.append("== ê´€ë ¨ ë¬¸ì„œ ë‚´ìš© ==")
            for i, doc in enumerate(documents[:3], 1):
                prompt_parts.append(f"{i}. {doc.strip()}")
            prompt_parts.append("")
        
        # ì°¨íŠ¸ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if chart_data:
            prompt_parts.extend([
                "== ì§‘ê³„ëœ ì°¨íŠ¸ ë°ì´í„° ==",
                f"ì œëª©: {chart_data.get('title', 'N/A')}",
                f"ë°ì´í„°: {chart_data.get('data', [])}",
                f"ë¼ë²¨: {chart_data.get('labels', [])}",
                ""
            ])
        
        final_prompt = "\n".join(prompt_parts)
        self.logger.info(f"ğŸ“ [PROMPT_GENERATED] ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(final_prompt)}ì")
        self.logger.info(f"ğŸ“ [PROMPT_CONTENT] í”„ë¡¬í”„íŠ¸ ë‚´ìš©:\n{final_prompt[:500]}...")
        
        return final_prompt
    
    def _try_direct_answer(self, question: str) -> Optional[str]:
        """ê°„ë‹¨í•œ ì§ˆë¬¸ë“¤ì— ëŒ€í•´ ì§ì ‘ ê³„ì‚°í•˜ì—¬ ë‹µë³€ (í†µí•© ê³„ì‚° ê¸°ë°˜)"""
        if not self.data_service.data_loaded:
            return None
            
        question_lower = question.lower()
        
        try:
            # ğŸ”„ í†µí•© ê³„ì‚° ë©”ì„œë“œ ì‚¬ìš©
            unified_stats = self.data_service.get_unified_inventory_stats()
            
            if "error" in unified_stats:
                return None
            
            # ì´ ì¬ê³ ëŸ‰ ì§ˆë¬¸
            if any(word in question_lower for word in ['ì´ ì¬ê³ ëŸ‰', 'ì´ì¬ê³ ', 'ì „ì²´ ì¬ê³ ', 'ì´ ì¬ê³ ']):
                total_inventory = unified_stats["total_inventory"]
                product_count = unified_stats["total_products"]
                calculation_method = unified_stats["calculation_method"]
                
                return f"ì´ ì¬ê³ ëŸ‰ì€ {total_inventory:,}ê°œì…ë‹ˆë‹¤. ì „ì²´ ì œí’ˆ ìˆ˜ëŠ” {product_count}ê°œì…ë‹ˆë‹¤."
            
            # ì…ê³ ëŸ‰ ì§ˆë¬¸ (í†µí•© ê³„ì‚° ê¸°ë°˜)
            if any(word in question_lower for word in ['ì…ê³ ëŸ‰', 'ì…ê³  í˜„í™©', 'ì˜¤ëŠ˜ ì…ê³ ']):
                total_inbound = unified_stats["total_inbound_qty"]
                daily_inbound = unified_stats["daily_inbound_avg"]
                
                return f"ì´ ì…ê³ ëŸ‰ì€ {total_inbound:,}ê°œì…ë‹ˆë‹¤. ì¼í‰ê·  ì…ê³ ëŸ‰ì€ {daily_inbound:,}ê°œì…ë‹ˆë‹¤."
            
            # ì¶œê³ ëŸ‰ ì§ˆë¬¸ (í†µí•© ê³„ì‚° ê¸°ë°˜)
            elif any(word in question_lower for word in ['ì¶œê³ ëŸ‰', 'ì¶œê³  í˜„í™©', 'ì˜¤ëŠ˜ ì¶œê³ ']):
                total_outbound = unified_stats["total_outbound_qty"]
                daily_outbound = unified_stats["daily_outbound_avg"]
                
                return f"ì´ ì¶œê³ ëŸ‰ì€ {total_outbound:,}ê°œì…ë‹ˆë‹¤. ì¼í‰ê·  ì¶œê³ ëŸ‰ì€ {daily_outbound:,}ê°œì…ë‹ˆë‹¤."
            
            # ë™ ê´€ë ¨ ì§ˆë¬¸ (í†µí•© ê³„ì‚° ê¸°ë°˜)
            elif any(word in question_lower for word in ['ë™', 'rack', 'aë™', 'bë™', 'cë™']):
                rack_distribution = unified_stats["rack_distribution"]
                rack_column = unified_stats["rack_column_used"]
                
                if rack_distribution:
                    # ìƒìœ„ 5ê°œ ë™ ì •ë³´
                    sorted_racks = sorted(rack_distribution.items(), key=lambda x: x[1], reverse=True)
                    rack_info = []
                    for rack, qty in sorted_racks[:5]:
                        rack_info.append(f"â€¢ {rack}ë™: {int(qty):,}ê°œ")
                    
                    return f"ë™ë³„ ì¬ê³  í˜„í™© (ìƒìœ„ 5ê°œ):\n{chr(10).join(rack_info)}\n\nì´ ë™ ìˆ˜: {len(rack_distribution)}ê°œ"
                else:
                    return "ë™ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            print(f"ì§ì ‘ ë‹µë³€ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return None
        
        return None
    
    async def _handle_self_rag_query(self, question: str) -> Optional[str]:
        """SELF-RAG ì „ìš© ì§ˆë¬¸ ì²˜ë¦¬"""
        try:
            self.logger.info(f"ğŸ§  SELF-RAG ì „ìš© ì²˜ë¦¬: {question}")
            return await self.langchain_service.process_with_self_rag(question)
        except Exception as e:
            self.logger.error(f"SELF-RAG ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    async def _handle_enhanced_vector_fallback(self, question: str) -> Optional[str]:
        """ğŸ”¥ ê°•í™”ëœ ë²¡í„° ê²€ìƒ‰ fallback - SELF-RAG ì‹¤íŒ¨ ì‹œ ì „ì²´ ë²¡í„° ê²€ìƒ‰ í™œìš©"""
        if not (self.vector_db_service and self.vector_db_service.is_initialized):
            self.logger.warning("ë²¡í„° DB ì„œë¹„ìŠ¤ ì—†ìŒ - enhanced fallback ë¶ˆê°€")
            return None
        
        try:
            self.logger.info(f"ğŸ” ê°•í™”ëœ ë²¡í„° fallback ì²˜ë¦¬: {question[:50]}...")
            
            # ğŸš€ 1ë‹¨ê³„: ë” ë„“ì€ ë²”ìœ„ë¡œ ë²¡í„° ê²€ìƒ‰
            search_result = await self.vector_db_service.search_relevant_data(
                query=question,
                n_results=25  # SELF-RAG ì‹¤íŒ¨ ì‹œ ë” ë§ì€ ë¬¸ì„œ ìˆ˜ì§‘
            )
            
            if not search_result.get("success") or search_result.get("found_documents", 0) == 0:
                self.logger.warning("ê°•í™”ëœ ë²¡í„° ê²€ìƒ‰ë„ ì‹¤íŒ¨")
                return None
            
            # ğŸš€ 2ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë” ìƒì„¸í•˜ê²Œ ë¶„ì„
            enhanced_context = self._build_enhanced_fallback_context(search_result, question)
            
            # ğŸš€ 3ë‹¨ê³„: AIì—ê²Œ ë” êµ¬ì²´ì ì¸ ì§€ì‹œì‚¬í•­ê³¼ í•¨ê»˜ ë‹µë³€ ìš”ì²­
            fallback_prompt = f"""
ë‹¹ì‹ ì€ ì°½ê³  ê´€ë¦¬ ì „ë¬¸ AIì…ë‹ˆë‹¤. SELF-RAG ì‹œìŠ¤í…œì´ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.

**í˜„ì¬ ìƒí™©:**
- í˜„ì¬ ë‚ ì§œ: {self.langchain_service.current_datetime.strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}
- ë°ì´í„° ë²”ìœ„: 2025ë…„ 1ì›” 1ì¼~7ì¼ (ê³¼ê±° ë°ì´í„°)
- ê³ ê¸‰ ì²˜ë¦¬ ì‹¤íŒ¨ë¡œ ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ í™œìš©

**ì§ˆë¬¸:** {question}

{enhanced_context}

**ê°•í™”ëœ ë‹µë³€ ê·œì¹™:**
1. ğŸ• **í˜„ì¬ ë‚ ì§œ í•„ìˆ˜ ëª…ì‹œ**: {self.langchain_service.current_datetime.strftime('%Yë…„ %mì›” %dì¼')}
2. ğŸ“… **ë°ì´í„° ë‚ ì§œ êµ¬ë¶„**: "ê³¼ê±° ë°ì´í„°(2025ë…„ 1ì›”)"ì„ì„ ë°˜ë“œì‹œ ëª…ì‹œ
3. ğŸ” **êµ¬ì²´ì  ì •ë³´ í™œìš©**: íšŒì‚¬ëª…, ìƒí’ˆëª…, ìˆ˜ëŸ‰ ë“± ê²€ìƒ‰ëœ êµ¬ì²´ì  ì •ë³´ ìµœëŒ€í•œ í™œìš©
4. âœ… **ìƒì„¸ ë‹µë³€**: ê°„ë‹¨íˆ ë‹µí•˜ì§€ ë§ê³  ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì„¤ëª…
5. âš ï¸ **ë¶ˆí™•ì‹¤ì„± í‘œì‹œ**: ì¶”ì •ì´ë‚˜ ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ ëª…ì‹œì ìœ¼ë¡œ êµ¬ë¶„
6. ğŸ“Š **ì¶œì²˜ ëª…ì‹œ**: ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜ì™€ ì •ë³´ ì¶œì²˜ í‘œì‹œ

**ë‹µë³€ ì‹œì‘ ì˜ˆì‹œ:**
"í˜„ì¬ ë‚ ì§œ({self.langchain_service.current_datetime.strftime('%Yë…„ %mì›” %dì¼')})ì™€ ê²€ìƒ‰ëœ ê³¼ê±° ë°ì´í„°(2025ë…„ 1ì›”)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì”€ë“œë¦¬ë©´..."

ë‹µë³€:"""
            
            response = await self.llm_client.answer_simple_query(fallback_prompt, {"enhanced_fallback": True})
            
            # ê²€ì¦ ì •ë³´ ì¶”ê°€
            found_docs = search_result.get("found_documents", 0)
            response += f"\n\nğŸ” *ê°•í™”ëœ fallbackìœ¼ë¡œ {found_docs}ê°œ ë¬¸ì„œë¥¼ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.*"
            response += f"\nâš ï¸ *ê³ ê¸‰ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì¼ì‹œ ë¶ˆê°€ë¡œ ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í–ˆìŠµë‹ˆë‹¤.*"
            
            # ì‘ë‹µ ì •ì œ ì ìš©
            cleaned_response = self.langchain_service._clean_response(
                response, question, 
                is_simple_question=self.langchain_service._is_simple_question_type(question)
            )
            
            self.logger.info("âœ… ê°•í™”ëœ ë²¡í„° fallback ì„±ê³µ")
            return cleaned_response
            
        except Exception as e:
            self.logger.error(f"ê°•í™”ëœ ë²¡í„° fallback ì‹¤íŒ¨: {e}")
            return None
    
    def _build_enhanced_fallback_context(self, search_result: dict, question: str) -> str:
        """ê°•í™”ëœ fallbackìš© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        documents = search_result.get("documents", [])
        metadata = search_result.get("metadata_summary", {})
        chart_data = search_result.get("chart_data", {})
        found_docs = search_result.get("found_documents", 0)
        
        context_parts = []
        
        # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
        context_parts.append(f"**ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:**")
        context_parts.append(f"- ì´ ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ: {found_docs}ê°œ (ì „ì²´ 2,900ê°œ ì¤‘)")
        context_parts.append(f"- ê²€ìƒ‰ í‚¤ì›Œë“œ: {question}")
        context_parts.append("")
        
        # í•µì‹¬ ë¬¸ì„œ ë‚´ìš© (ë” ë§ì´ í¬í•¨)
        if documents:
            context_parts.append(f"**í•µì‹¬ ê´€ë ¨ ë¬¸ì„œ ë‚´ìš© (ìƒìœ„ {min(len(documents), 8)}ê°œ):**")
            for i, doc in enumerate(documents[:8], 1):
                context_parts.append(f"{i}. {doc.strip()}")
            context_parts.append("")
        
        # ë©”íƒ€ë°ì´í„° ì •ë³´
        if metadata:
            context_parts.append(f"**ë°ì´í„° ë©”íƒ€ ì •ë³´:**")
            for key, value in metadata.items():
                context_parts.append(f"- {key}: {value}")
            context_parts.append("")
        
        # ì°¨íŠ¸ ë°ì´í„° (ì§‘ê³„ ì •ë³´)
        if chart_data:
            context_parts.append(f"**ì§‘ê³„ ë°ì´í„°:**")
            if 'title' in chart_data:
                context_parts.append(f"- ì°¨íŠ¸ ì œëª©: {chart_data['title']}")
            if 'data' in chart_data and 'labels' in chart_data:
                data_dict = dict(zip(chart_data.get('labels', []), chart_data.get('data', [])))
                context_parts.append(f"- ì§‘ê³„ ê²°ê³¼: {data_dict}")
            context_parts.append("")
        
        return "\n".join(context_parts)
    
    def _get_system_status(self) -> str:
        """í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½"""
        try:
            if self.vector_db_service and self.vector_db_service.is_initialized:
                return "ğŸŸ¢ **ì‹œìŠ¤í…œ ìƒíƒœ:** ë²¡í„° ê²€ìƒ‰ ê°€ëŠ¥ (2,900ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì™„ë£Œ)"
            else:
                return "ğŸŸ¡ **ì‹œìŠ¤í…œ ìƒíƒœ:** ë²¡í„° ê²€ìƒ‰ ì¼ì‹œ ë¶ˆê°€, ê¸°ë³¸ ë°ì´í„°ë¡œ ì‘ë‹µ"
        except:
            return "ğŸ”´ **ì‹œìŠ¤í…œ ìƒíƒœ:** ì¼ë¶€ ê¸°ëŠ¥ ì œí•œ"
    
    # ================== ì§ˆë¬¸ ìœ í˜•ë³„ ì „ìš© ì²˜ë¦¬ ë©”ì„œë“œ ==================
    
    async def _handle_date_analysis_query(self, question: str) -> Optional[str]:
        """ğŸ“… ë‚ ì§œ ë¶„ì„ ì „ìš© ì²˜ë¦¬ - "ì–¸ì œ", "ê°€ì¥ ë†’ì•˜ë˜ ë‚ " ë“±"""
        try:
            self.logger.info(f"ğŸ“… [DATE_ANALYSIS] ë‚ ì§œ ë¶„ì„ ì§ˆë¬¸ ì²˜ë¦¬: '{question}'")
            
            question_lower = question.lower()
            
            # ì…ê³ ëŸ‰ ìµœëŒ€ ë‚ ì§œ ë¶„ì„
            if "ì…ê³ ëŸ‰" in question_lower and ("ì œì¼" in question_lower or "ê°€ì¥" in question_lower or "ìµœëŒ€" in question_lower):
                return await self._analyze_max_inbound_date()
            
            # ì¶œê³ ëŸ‰ ìµœëŒ€ ë‚ ì§œ ë¶„ì„
            elif "ì¶œê³ ëŸ‰" in question_lower and ("ì œì¼" in question_lower or "ê°€ì¥" in question_lower or "ìµœëŒ€" in question_lower):
                return await self._analyze_max_outbound_date()
            
            # ì¼ë°˜ì ì¸ ë‚ ì§œ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰
            else:
                return await self._handle_vector_search_query(question)
                
        except Exception as e:
            self.logger.error(f"âŒ [DATE_ANALYSIS] ë‚ ì§œ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None
    
    async def _analyze_max_inbound_date(self) -> str:
        """ì…ê³ ëŸ‰ì´ ê°€ì¥ ë†’ì•˜ë˜ ë‚  ë¶„ì„"""
        try:
            if not self.data_service.data_loaded or self.data_service.inbound_data is None:
                return "ğŸ“… ì…ê³  ë°ì´í„°ê°€ ì—†ì–´ ë‚ ì§œë³„ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ë‚ ì§œë³„ ì…ê³ ëŸ‰ ì§‘ê³„
            daily_inbound = self.data_service.inbound_data.groupby('Date')['PalleteQty'].sum().sort_values(ascending=False)
            
            if len(daily_inbound) > 0:
                max_date = daily_inbound.index[0]
                max_quantity = int(daily_inbound.iloc[0])
                
                # ìƒìœ„ 3ì¼ ì •ë³´ í¬í•¨
                top_3 = []
                for i, (date, qty) in enumerate(daily_inbound.head(3).items()):
                    rank = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i]
                    top_3.append(f"{rank} {date}: {int(qty):,}ê°œ")
                
                return f"""ğŸ“… **ì…ê³ ëŸ‰ì´ ê°€ì¥ ë†’ì•˜ë˜ ë‚ ì€ {max_date}ì…ë‹ˆë‹¤.**

ğŸ“Š **ìƒì„¸ ì •ë³´:**
- **ìµœëŒ€ ì…ê³ ëŸ‰:** {max_quantity:,}ê°œ
- **í•´ë‹¹ ë‚ ì§œ:** {max_date}

ğŸ† **ìƒìœ„ 3ì¼ ìˆœìœ„:**
{chr(10).join(top_3)}

ğŸ’¡ ì´ ì •ë³´ëŠ” {len(daily_inbound)}ì¼ê°„ì˜ ì‹¤ì œ ì…ê³  ë°ì´í„°ë¥¼ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤."""
            else:
                return "ğŸ“… ì…ê³  ë°ì´í„°ì—ì„œ ë‚ ì§œë³„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
        except Exception as e:
            self.logger.error(f"âŒ ìµœëŒ€ ì…ê³ ì¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "ğŸ“… ì…ê³ ëŸ‰ ë‚ ì§œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _analyze_max_outbound_date(self) -> str:
        """ì¶œê³ ëŸ‰ì´ ê°€ì¥ ë†’ì•˜ë˜ ë‚  ë¶„ì„"""
        try:
            if not self.data_service.data_loaded or self.data_service.outbound_data is None:
                return "ğŸ“… ì¶œê³  ë°ì´í„°ê°€ ì—†ì–´ ë‚ ì§œë³„ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ë‚ ì§œë³„ ì¶œê³ ëŸ‰ ì§‘ê³„
            daily_outbound = self.data_service.outbound_data.groupby('Date')['PalleteQty'].sum().sort_values(ascending=False)
            
            if len(daily_outbound) > 0:
                max_date = daily_outbound.index[0]
                max_quantity = int(daily_outbound.iloc[0])
                
                # ìƒìœ„ 3ì¼ ì •ë³´ í¬í•¨
                top_3 = []
                for i, (date, qty) in enumerate(daily_outbound.head(3).items()):
                    rank = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i]
                    top_3.append(f"{rank} {date}: {int(qty):,}ê°œ")
                
                return f"""ğŸ“… **ì¶œê³ ëŸ‰ì´ ê°€ì¥ ë†’ì•˜ë˜ ë‚ ì€ {max_date}ì…ë‹ˆë‹¤.**

ğŸ“Š **ìƒì„¸ ì •ë³´:**
- **ìµœëŒ€ ì¶œê³ ëŸ‰:** {max_quantity:,}ê°œ
- **í•´ë‹¹ ë‚ ì§œ:** {max_date}

ğŸ† **ìƒìœ„ 3ì¼ ìˆœìœ„:**
{chr(10).join(top_3)}

ğŸ’¡ ì´ ì •ë³´ëŠ” {len(daily_outbound)}ì¼ê°„ì˜ ì‹¤ì œ ì¶œê³  ë°ì´í„°ë¥¼ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤."""
            else:
                return "ğŸ“… ì¶œê³  ë°ì´í„°ì—ì„œ ë‚ ì§œë³„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
        except Exception as e:
            self.logger.error(f"âŒ ìµœëŒ€ ì¶œê³ ì¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "ğŸ“… ì¶œê³ ëŸ‰ ë‚ ì§œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _handle_status_analysis_query(self, question: str) -> Optional[str]:
        """ğŸ“Š ìƒíƒœ ë¶„ì„ ì „ìš© ì²˜ë¦¬ - "ë¶€ì¡±í•œ", "ìœ„í—˜í•œ" ë“±"""
        try:
            self.logger.info(f"ğŸ“Š [STATUS_ANALYSIS] ìƒíƒœ ë¶„ì„ ì§ˆë¬¸ ì²˜ë¦¬: '{question}'")
            
            question_lower = question.lower()
            
            # ì¬ê³  ë¶€ì¡± ì œí’ˆ ë¶„ì„
            if "ë¶€ì¡±í•œ" in question_lower and "ì œí’ˆ" in question_lower:
                return await self._analyze_low_stock_products()
            
            # ìœ„í—˜ ì¬ê³  ì œí’ˆ ë¶„ì„
            elif "ìœ„í—˜í•œ" in question_lower or "ìœ„í—˜" in question_lower:
                return await self._analyze_risk_products()
            
            # ì¼ë°˜ì ì¸ ìƒíƒœ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰
            else:
                return await self._handle_vector_search_query(question)
                
        except Exception as e:
            self.logger.error(f"âŒ [STATUS_ANALYSIS] ìƒíƒœ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None
    
    async def _analyze_low_stock_products(self) -> str:
        """ì¬ê³  ë¶€ì¡± ì œí’ˆ ë¶„ì„"""
        try:
            if not self.data_service.data_loaded or self.data_service.product_master is None:
                return "ğŸ“Š ì œí’ˆ ë°ì´í„°ê°€ ì—†ì–´ ì¬ê³  ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # í˜„ì¬ê³  ê¸°ì¤€ìœ¼ë¡œ ë¶€ì¡± ì œí’ˆ ì°¾ê¸° (ì„ê³„ê°’: 20ê°œ ì´í•˜)
            low_stock_threshold = 20
            stock_column = 'í˜„ì¬ê³ ' if 'í˜„ì¬ê³ ' in self.data_service.product_master.columns else 'Start Pallete Qty'
            
            low_stock_products = self.data_service.product_master[
                self.data_service.product_master[stock_column] <= low_stock_threshold
            ].sort_values(stock_column)
            
            if len(low_stock_products) > 0:
                # ìƒìœ„ 5ê°œ ë¶€ì¡± ì œí’ˆ
                product_list = []
                for idx, (_, product) in enumerate(low_stock_products.head(5).iterrows()):
                    danger_level = "ğŸš¨" if product[stock_column] <= 5 else "âš ï¸" if product[stock_column] <= 10 else "ğŸ“¦"
                    product_name = product.get('ProductName', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    current_stock = int(product[stock_column])
                    rack_info = product.get('ë™ìœ„ì¹˜', product.get('Rack Name', 'ì•Œ ìˆ˜ ì—†ìŒ'))
                    
                    product_list.append(f"{danger_level} **{product_name}**: {current_stock}ê°œ ({rack_info}ë™)")
                
                return f"""ğŸ“Š **ì¬ê³ ê°€ ë¶€ì¡±í•œ ì œí’ˆ ë¶„ì„ ê²°ê³¼:**

ğŸš¨ **ìœ„í—˜ ìˆ˜ì¤€ ê¸°ì¤€:**
- ğŸš¨ ì‹¬ê° (5ê°œ ì´í•˜)
- âš ï¸ ì£¼ì˜ (6-10ê°œ)  
- ğŸ“¦ ë¶€ì¡± (11-20ê°œ)

ğŸ“¦ **ë¶€ì¡± ì œí’ˆ ëª©ë¡ (ìƒìœ„ 5ê°œ):**
{chr(10).join(product_list)}

ğŸ“Š **í†µê³„:**
- **ì´ ë¶€ì¡± ì œí’ˆ:** {len(low_stock_products)}ê°œ
- **ë¶„ì„ ê¸°ì¤€:** {low_stock_threshold}ê°œ ì´í•˜
- **ì „ì²´ ì œí’ˆ ìˆ˜:** {len(self.data_service.product_master)}ê°œ

ğŸ’¡ **ê¶Œì¥ ì‚¬í•­:**
ì¦‰ì‹œ ë°œì£¼ê°€ í•„ìš”í•œ ì œí’ˆë“¤ì´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ğŸš¨ í‘œì‹œ ì œí’ˆì€ ê¸´ê¸‰ ë³´ì¶©ì´ í•„ìš”í•©ë‹ˆë‹¤."""
            else:
                return f"""âœ… **ì¬ê³  ë¶€ì¡± ì œí’ˆ ì—†ìŒ**

ğŸ“Š **ë¶„ì„ ê²°ê³¼:**
- **ë¶„ì„ ê¸°ì¤€:** {low_stock_threshold}ê°œ ì´í•˜
- **ì „ì²´ ì œí’ˆ ìˆ˜:** {len(self.data_service.product_master)}ê°œ
- **ê²°ê³¼:** ëª¨ë“  ì œí’ˆì´ ì•ˆì „ ì¬ê³  ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ğŸ‰ í˜„ì¬ ì¬ê³  ê´€ë¦¬ê°€ ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤."""
                
        except Exception as e:
            self.logger.error(f"âŒ ì¬ê³  ë¶€ì¡± ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "ğŸ“Š ì¬ê³  ë¶€ì¡± ì œí’ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _analyze_risk_products(self) -> str:
        """ìœ„í—˜ ì¬ê³  ì œí’ˆ ë¶„ì„ (ë§¤ìš° ë‚®ì€ ì¬ê³ )"""
        try:
            if not self.data_service.data_loaded or self.data_service.product_master is None:
                return "ğŸ“Š ì œí’ˆ ë°ì´í„°ê°€ ì—†ì–´ ìœ„í—˜ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ìœ„í—˜ ì„ê³„ê°’: 10ê°œ ì´í•˜
            risk_threshold = 10
            stock_column = 'í˜„ì¬ê³ ' if 'í˜„ì¬ê³ ' in self.data_service.product_master.columns else 'Start Pallete Qty'
            
            risk_products = self.data_service.product_master[
                self.data_service.product_master[stock_column] <= risk_threshold
            ].sort_values(stock_column)
            
            if len(risk_products) > 0:
                return f"""ğŸš¨ **ìœ„í—˜ ì¬ê³  ì œí’ˆ {len(risk_products)}ê°œ ë°œê²¬!**

âš ï¸ **ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”:**
{chr(10).join([f"- {product.get('ProductName', 'ì•Œ ìˆ˜ ì—†ìŒ')}: {int(product[stock_column])}ê°œ" for _, product in risk_products.head(5).iterrows()])}

ğŸš¨ **ê¸´ê¸‰ ê¶Œì¥ ì‚¬í•­:**
1. ì¦‰ì‹œ ë°œì£¼ ì²˜ë¦¬
2. ê³ ê° ì£¼ë¬¸ ì œí•œ ê²€í† 
3. ëŒ€ì²´ ìƒí’ˆ ì¤€ë¹„"""
            else:
                return "âœ… **ìœ„í—˜ ìˆ˜ì¤€ì˜ ì¬ê³  ë¶€ì¡± ì œí’ˆì€ ì—†ìŠµë‹ˆë‹¤.**"
                
        except Exception as e:
            self.logger.error(f"âŒ ìœ„í—˜ ì¬ê³  ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "ğŸš¨ ìœ„í—˜ ì¬ê³  ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _handle_list_query(self, question: str) -> Optional[str]:
        """ğŸ“‹ ëª©ë¡ ì¡°íšŒ ì „ìš© ì²˜ë¦¬ - "ì–´ë–¤", "ì–´ëŠ", "ëª©ë¡" ë“±"""
        try:
            self.logger.info(f"ğŸ“‹ [LIST_QUERY] ëª©ë¡ ì¡°íšŒ ì§ˆë¬¸ ì²˜ë¦¬: '{question}'")
            
            # ëª©ë¡ ì¡°íšŒëŠ” ë²¡í„° ê²€ìƒ‰ì´ ê°€ì¥ ì í•©í•˜ë¯€ë¡œ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì²˜ë¦¬
            return await self._handle_vector_search_query(question)
                
        except Exception as e:
            self.logger.error(f"âŒ [LIST_QUERY] ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    async def _handle_rack_specific_query(self, question: str) -> Optional[str]:
        """ğŸ—ï¸ ë™ ê´€ë ¨ ì§ˆë¬¸ ì „ìš© ì²˜ë¦¬ - CoT ê²°ê³¼ì™€ ë¬´ê´€í•˜ê²Œ ìš°ì„  ì ìš©"""
        try:
            self.logger.info(f"ğŸ—ï¸ [RACK_QUERY] ë™ ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬: '{question}'")
            
            question_lower = question.lower()
            
            # ğŸ¯ íŠ¹ì • ë™ ì‹ë³„ (A~Z ë™)
            import re
            rack_pattern = re.search(r'([a-z])ë™|([a-z])\s*rack|rack\s*([a-z])', question_lower)
            
            if rack_pattern:
                # ë§¤ì¹­ëœ ë™ ë¬¸ì ì¶”ì¶œ
                rack_letter = (rack_pattern.group(1) or rack_pattern.group(2) or rack_pattern.group(3)).upper()
                self.logger.info(f"ğŸ¯ [RACK_IDENTIFIED] íŠ¹ì • ë™ ì‹ë³„: {rack_letter}ë™")
                
                # ì§ì ‘ ë™ ë°ì´í„° ì¡°íšŒ
                rack_data = self._get_rack_specific_data(rack_letter)
                
                if rack_data:
                    rack_name = rack_data.get('rack_name', f'{rack_letter}ë™')
                    current_stock = rack_data.get('current_stock', 0)
                    utilization_rate = rack_data.get('utilization_rate', 0)
                    products = rack_data.get('products', ['ì •ë³´ ì—†ìŒ'])
                    product_count = rack_data.get('product_count', 0)
                    status = rack_data.get('status', 'âš ï¸ ì•Œ ìˆ˜ ì—†ìŒ')
                    found_method = rack_data.get('found_method', 'legacy')
                    
                    # ğŸ¯ ìƒìœ„ 3ê°œ ìƒí’ˆëª… í‘œì‹œ
                    top_products = ', '.join(products[:3]) if len(products) > 0 else 'ì •ë³´ ì—†ìŒ'
                    if len(products) > 3:
                        top_products += f" ì™¸ {len(products) - 3}ê°œ"
                    
                    data_quality = "âœ… í†µí•© ê³„ì‚° ê¸°ë°˜" if found_method == 'unified_calculation' else "âš ï¸ ë ˆê±°ì‹œ ë°©ì‹"
                    
                    return f"{rack_name} ì¬ê³  í˜„í™©: í˜„ì¬ ì¬ê³ ëŸ‰ {current_stock:,}ê°œ, í™œìš©ë¥  {utilization_rate:.1f}%, ì €ì¥ ìƒí’ˆ {top_products}, ìƒí’ˆ ì¢…ë¥˜ {product_count}ê°œ"
                else:
                    return f"{rack_letter}ë™ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë™ ì´ë¦„ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."
            
            # ì¼ë°˜ ë™ ê´€ë ¨ ì§ˆë¬¸ì€ ê¸°ì¡´ fallbackìœ¼ë¡œ ì²˜ë¦¬
            else:
                self.logger.info("ğŸ—ï¸ [RACK_GENERAL] ì¼ë°˜ ë™ ì§ˆë¬¸ìœ¼ë¡œ fallback ì²˜ë¦¬")
                return await self._fallback_data_query(question)
                
        except Exception as e:
            self.logger.error(f"âŒ [RACK_QUERY] ë™ ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None