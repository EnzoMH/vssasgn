from ..services.ai_service import WarehouseAI
from ..services.data_service import DataService
import logging
import asyncio
from typing import Dict, Any, Optional

class WarehouseChatbot:
    def __init__(self, data_service=None, vector_db_service=None):
        self.data_service = data_service or DataService()
        self.vector_db_service = vector_db_service
        self.llm_client = WarehouseAI() # WarehouseAI ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        self.logger = logging.getLogger(__name__)
        
        # ì²˜ë¦¬ ì²´ì¸ ì„¤ì •
        self.processing_chains = {
            "direct": self._handle_direct_query,
            "vector_search": self._handle_vector_search_query, 
            "general": self._handle_general_query
        }

    def analyze_intent(self, question: str):
        # ì§ˆë¬¸ì—ì„œ ì˜ë„ ë¶„ì„ (ì˜ˆ: "ì¬ê³ ", "ì¶œê³ ëŸ‰", "ì˜ˆì¸¡")
        if "ì¬ê³ " in question:
            return "inventory"
        elif "ì¶œê³ ëŸ‰" in question:
            return "outbound"
        elif "ì˜ˆìƒ" in question or "ì˜ˆì¸¡" in question:
            return "prediction"
        else:
            return "general"

    async def process_query(self, question: str) -> str:
        """
        ê°œì„ ëœ ì²´ì¸ ê¸°ë°˜ ì§ˆì˜ ì²˜ë¦¬
        1. Direct Answer (ë¹ ë¥¸ ê³„ì‚° ê²°ê³¼)
        2. Vector Search (ê³ ê¸‰ ê²€ìƒ‰)  
        3. General LLM (ì¼ë°˜ ì§ˆì˜ì‘ë‹µ)
        """
        try:
            self.logger.info(f"ì§ˆì˜ ì²˜ë¦¬ ì‹œì‘: {question[:50]}...")
            
            # 1ë‹¨ê³„: ì§ì ‘ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸ì¸ì§€ í™•ì¸
            direct_result = await self._handle_direct_query(question)
            if direct_result:
                self.logger.info("ì§ì ‘ ë‹µë³€ìœ¼ë¡œ ì²˜ë¦¬ ì™„ë£Œ")
                return direct_result
            
            # 2ë‹¨ê³„: CoTë¥¼ í†µí•œ VectorDB ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨
            needs_vector = await self._needs_vector_search(question)
            if needs_vector:
                self.logger.info("CoT ë¶„ì„ ê²°ê³¼: VectorDB ê²€ìƒ‰ ì²´ì¸ìœ¼ë¡œ ì²˜ë¦¬")
                vector_result = await self._handle_vector_search_query(question)
                if vector_result:
                    return vector_result
            else:
                self.logger.info("CoT ë¶„ì„ ê²°ê³¼: VectorDB ê²€ìƒ‰ ë¶ˆí•„ìš”")
            
            # 3ë‹¨ê³„: ì¼ë°˜ LLM ì²˜ë¦¬
            self.logger.info("ì¼ë°˜ LLM ì²´ì¸ìœ¼ë¡œ ì²˜ë¦¬")
            return await self._handle_general_query(question)
            
        except Exception as e:
            self.logger.error(f"ì§ˆì˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def _needs_vector_search(self, question: str) -> bool:
        """CoTë¥¼ í†µí•œ ì˜ë¯¸ë¡ ì  ë¶„ì„ìœ¼ë¡œ VectorDB ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨"""
        try:
            # 1ë‹¨ê³„: ê¸°ë³¸ í‚¤ì›Œë“œ í•„í„°ë§ (ì„±ëŠ¥ ìµœì í™”)
            basic_keywords = [
                "ì–´ë–¤", "ì–´ë””", "ëˆ„ê°€", "ì–¸ì œ", "ì–¼ë§ˆ", "ëª‡", "ì–¼ë§ˆë‚˜", "ë¬´ì—‡", "ë­", "ë­”ê°€",
                "ë¦¬ìŠ¤íŠ¸", "ëª©ë¡", "í˜„í™©", "ìƒíƒœ", "í†µê³„", "ì¡°íšŒ", "ê²€ìƒ‰", "ë¶„ì„", "ì£¼ìš”",
                "supplier", "ê³µê¸‰ì—…ì²´", "ê³µê¸‰ì‚¬", "ê³ ê°ì‚¬", "ì—…ì²´", "íšŒì‚¬", "ê¸°ì—…", 
                "product", "ìƒí’ˆ", "ì œí’ˆ", "í’ˆëª©", "ë™", "rack", "ì¬ê³ ", "ìˆ˜ëŸ‰", "aë™", "bë™"
            ]
            
            question_lower = question.lower()
            has_basic_keywords = any(keyword in question_lower for keyword in basic_keywords)
            
            if not has_basic_keywords:
                return False
            
            # 2ë‹¨ê³„: ê°„ë‹¨í•œ íŒ¨í„´ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§
            simple_calc_patterns = ["ì´ ì¬ê³ ëŸ‰", "ì´ì¬ê³ ", "ì „ì²´ ì¬ê³ ëŸ‰", "í˜„ì¬ ì¬ê³ ëŸ‰ì´ ì–¼ë§ˆ"]
            if any(pattern in question_lower for pattern in simple_calc_patterns):
                self.logger.info("ì‚¬ì „ í•„í„°ë§: ê°„ë‹¨í•œ ê³„ì‚° ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨")
                return False
            
            # ë²¡í„° ê²€ìƒ‰ í•„ìˆ˜ íŒ¨í„´
            vector_required_patterns = ["ì–´ë–¤ ìƒí’ˆ", "ì–´ë–¤ ì—…ì²´", "ì£¼ìš” ê³µê¸‰", "ì£¼ìš” ìƒí’ˆ", "aë™", "bë™", "ë™ì—"]
            if any(pattern in question_lower for pattern in vector_required_patterns):
                self.logger.info("ì‚¬ì „ í•„í„°ë§: ë²¡í„° ê²€ìƒ‰ í•„ìˆ˜ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨")
                return True
            
            # 3ë‹¨ê³„: CoT ê¸°ë°˜ ì˜ë¯¸ë¡ ì  ë¶„ì„ (ë³µì¡í•œ ì¼€ì´ìŠ¤ë§Œ)
            cot_analysis = await self._analyze_question_intent_with_cot(question)
            
            # 4ë‹¨ê³„: CoT ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… íŒë‹¨
            needs_vector = cot_analysis.get("needs_vector_search", False)
            confidence = cot_analysis.get("confidence", 0.5)
            reasoning = cot_analysis.get("reasoning", "")
            
            self.logger.info(f"CoT ë¶„ì„ ê²°ê³¼: needs_vector={needs_vector}, confidence={confidence}, reasoning={reasoning[:100]}...")
            
            return needs_vector
            
        except Exception as e:
            self.logger.warning(f"CoT ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ fallback: {e}")
            # fallback: ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­
            basic_vector_keywords = [
                "ë¶„ì„", "íŠ¸ë Œë“œ", "íŒ¨í„´", "ì˜ˆì¸¡", "supplier", "ê³µê¸‰ì—…ì²´", "ê³ ê°ì‚¬",
                "ìƒí’ˆ", "ì œí’ˆ", "ë™", "ì¬ê³ ", "ì–´ë–¤", "ì–´ë””", "ëˆ„ê°€", "ì–¼ë§ˆ"
            ]
            return any(keyword in question_lower for keyword in basic_vector_keywords)
    
    async def _analyze_question_intent_with_cot(self, question: str) -> Dict[str, Any]:
        """Chain of Thoughtë¥¼ í†µí•œ ì§ˆë¬¸ ì˜ë„ ë¶„ì„"""
        try:
            if not self.llm_client:
                return {"needs_vector_search": False, "reasoning": "LLM í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ"}
            
            cot_prompt = f"""
ë‹¹ì‹ ì€ ì°½ê³  ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ì§ˆì˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì„ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ì²˜ë¦¬ ë°©ì‹ì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ì„¸ìš”.

**ì§ˆë¬¸:** "{question}"

**ë¶„ì„ ë‹¨ê³„:**
1. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜: ì´ ì§ˆë¬¸ì´ ìš”êµ¬í•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€?
2. ë°ì´í„° ë²”ìœ„ íŒë‹¨: ë‹¨ìˆœ ê³„ì‚°ì¸ê°€, ë³µí•© ê²€ìƒ‰ì¸ê°€?
3. ì²˜ë¦¬ ë°©ì‹ ê²°ì •: ì§ì ‘ ê³„ì‚°, ë²¡í„° ê²€ìƒ‰, ì¼ë°˜ LLM ì¤‘ ë¬´ì—‡ì´ ì í•©í•œê°€?

**íŒë‹¨ ê¸°ì¤€:**
- ì§ì ‘ ê³„ì‚°: "ì´ ì¬ê³ ëŸ‰", "ì „ì²´ ì…ê³ ëŸ‰" ë“± ë‹¨ìˆœ í•©ê³„ (ìˆ«ì í•˜ë‚˜ë§Œ ì›í•˜ëŠ” ê²½ìš°)
- ë²¡í„° ê²€ìƒ‰: "ì–´ë–¤ ì—…ì²´ë“¤", "ì–´ë–¤ ìƒí’ˆë“¤", "ì£¼ìš” ê³µê¸‰ì‚¬", "Aë™ ìƒí’ˆ", "ìƒìœ„ Nê°œ", "ëª©ë¡ ì¡°íšŒ", "í˜„í™© ë¶„ì„"
- ì¼ë°˜ LLM: ê°œë… ì„¤ëª…, ì‚¬ìš©ë²•, ì¼ë°˜ ìƒì‹

**ì¤‘ìš”:** ë‹¤ìŒ ì§ˆë¬¸ë“¤ì€ ë°˜ë“œì‹œ ë²¡í„° ê²€ìƒ‰ì´ í•„ìš”í•©ë‹ˆë‹¤:
- "Aë™ì— ì–´ë–¤ ìƒí’ˆì´ ìˆì§€?" â†’ ë²¡í„° ê²€ìƒ‰ (íŠ¹ì • ìœ„ì¹˜ ìƒí’ˆ ì¡°íšŒ)
- "ì£¼ìš” ê³µê¸‰ì‚¬ëŠ”?" â†’ ë²¡í„° ê²€ìƒ‰ (ê³µê¸‰ì—…ì²´ ëª©ë¡ ë° ìˆœìœ„)
- "ì£¼ìš” ìƒí’ˆì€?" â†’ ë²¡í„° ê²€ìƒ‰ (ìƒí’ˆ ëª©ë¡ ë° ë¶„ì„)
- "í˜„ì¬ ì¬ê³ ëŸ‰ì´ ì–¼ë§ˆì•¼?" â†’ ì§ì ‘ ê³„ì‚° (ë‹¨ìˆœ í•©ê³„)

**ì‘ë‹µ í˜•ì‹ (JSON):**
{{
    "question_type": "data_query|calculation|explanation|other",
    "data_scope": "simple|complex|none",
    "reasoning": "ë‹¨ê³„ë³„ ë¶„ì„ ê²°ê³¼",
    "needs_vector_search": true|false,
    "confidence": 0.0-1.0
}}
"""
            
            # ê°„ë‹¨í•œ LLM í˜¸ì¶œë¡œ CoT ë¶„ì„ ìˆ˜í–‰ (CoT í”Œë˜ê·¸ ì „ë‹¬)
            response = await self.llm_client.answer_simple_query(cot_prompt, {"cot_analysis": True})
            
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            import json
            try:
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    json_str = response[json_start:json_end]
                    analysis = json.loads(json_str)
                    
                    self.logger.info(f"CoT ë¶„ì„ ì™„ë£Œ: {analysis.get('reasoning', '')}")
                    return analysis
                else:
                    raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    
            except (json.JSONDecodeError, ValueError) as e:
                self.logger.warning(f"CoT JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                # ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ fallback
                return self._fallback_intent_analysis(question, response)
                
        except Exception as e:
            self.logger.warning(f"CoT ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"needs_vector_search": False, "reasoning": f"ë¶„ì„ ì‹¤íŒ¨: {e}"}
    
    def _fallback_intent_analysis(self, question: str, llm_response: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µ ê¸°ë°˜ fallback ì˜ë„ ë¶„ì„"""
        response_lower = llm_response.lower()
        
        # LLM ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ê°ì§€
        vector_indicators = [
            "ë²¡í„° ê²€ìƒ‰", "vector", "ë³µí•©", "ê²€ìƒ‰", "ì¡°íšŒ", "ë¶„ì„", 
            "ë°ì´í„°", "ëª©ë¡", "ë¹„êµ", "ìƒìœ„", "í•˜ìœ„"
        ]
        
        direct_indicators = [
            "ì§ì ‘", "ê³„ì‚°", "ë‹¨ìˆœ", "í•©ê³„", "ì´", "ê°„ë‹¨"
        ]
        
        has_vector_indicators = any(indicator in response_lower for indicator in vector_indicators)
        has_direct_indicators = any(indicator in response_lower for indicator in direct_indicators)
        
        if has_vector_indicators and not has_direct_indicators:
            return {
                "needs_vector_search": True,
                "reasoning": "LLM ì‘ë‹µì—ì„œ ë³µí•© ê²€ìƒ‰ í•„ìš”ì„± ê°ì§€",
                "confidence": 0.7
            }
        elif has_direct_indicators:
            return {
                "needs_vector_search": False,
                "reasoning": "LLM ì‘ë‹µì—ì„œ ì§ì ‘ ê³„ì‚° ê°€ëŠ¥ì„± ê°ì§€",
                "confidence": 0.8
            }
        else:
            # ì§ˆë¬¸ ìì²´ì—ì„œ ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­
            question_lower = question.lower()
            complex_patterns = ["ì–´ë–¤", "ì–´ëŠ", "ëˆ„ê°€", "ë­ê°€", "ë¬´ì—‡", "ë¦¬ìŠ¤íŠ¸", "ëª©ë¡", "ìƒìœ„", "í•˜ìœ„"]
            
            if any(pattern in question_lower for pattern in complex_patterns):
                return {
                    "needs_vector_search": True,
                    "reasoning": "ì§ˆë¬¸ì—ì„œ ë³µí•© ì¡°íšŒ íŒ¨í„´ ê°ì§€",
                    "confidence": 0.6
                }
            else:
                return {
                    "needs_vector_search": False,
                    "reasoning": "ë‹¨ìˆœ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨",
                    "confidence": 0.5
                }

    async def _handle_direct_query(self, question: str) -> Optional[str]:
        """ì§ì ‘ ê³„ì‚°ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ê°„ë‹¨í•œ ì§ˆë¬¸ ì²˜ë¦¬"""
        return self._try_direct_answer(question)
    
    async def _handle_vector_search_query(self, question: str) -> Optional[str]:
        """VectorDBë¥¼ í™œìš©í•œ ê³ ê¸‰ ê²€ìƒ‰ ì§ˆë¬¸ ì²˜ë¦¬"""
        if not (self.vector_db_service and self.vector_db_service.is_initialized):
            self.logger.info("VectorDB ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ, ì¼ë°˜ ì²˜ë¦¬ë¡œ ë„˜ì–´ê°")
            return None
            
        try:
            self.logger.info("VectorDB ê²€ìƒ‰ ì‹œì‘...")
            search_result = await self.vector_db_service.search_relevant_data(
                query=question,
                n_results=15  # ê³µê¸‰ì—…ì²´ ë“± ì§‘ê³„ë¥¼ ìœ„í•´ ë” ë§ì€ ê²°ê³¼ í•„ìš”
            )
            
            if not search_result.get("success"):
                self.logger.warning("VectorDB ê²€ìƒ‰ ì‹¤íŒ¨")
                return None
                
            # Vector ê²€ìƒ‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
            structured_context = self._vectordb_to_prompt(search_result, question)
            
            # ìµœì í™”ëœ VectorDB ì „ìš© LLM í˜¸ì¶œ
            response = await self.llm_client.answer_with_vector_context(
                question, structured_context
            )
            
            self.logger.info("VectorDB ê²€ìƒ‰ ì²˜ë¦¬ ì™„ë£Œ")
            return response
            
        except Exception as e:
            self.logger.error(f"VectorDB ê²€ìƒ‰ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None
    
    async def _handle_general_query(self, question: str) -> str:
        """ì¼ë°˜ì ì¸ ì§ˆë¬¸ì„ ê¸°ë³¸ ë°ì´í„°ë¡œ ì²˜ë¦¬"""
        intent = self.analyze_intent(question)
        context_data = self.data_service.get_relevant_data(intent)
        
        # ê°„ë‹¨í•œ LLM í˜¸ì¶œ (VectorDB ì—†ì´)
        return await self.llm_client.answer_simple_query(question, context_data)
    
    def _vectordb_to_prompt(self, search_result: Dict, question: str) -> str:
        """VectorDB ê²€ìƒ‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜"""
        documents = search_result.get('documents', [])
        chart_data = search_result.get('chart_data', {})
        metadata_summary = search_result.get('metadata_summary', {})
        
        prompt_parts = [
            f"ì§ˆë¬¸: {question}",
            "",
            "== ì‹¤ì œ ì°½ê³  ë°ì´í„° ê²€ìƒ‰ ê²°ê³¼ ==",
            f"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {search_result.get('found_documents', 0)}ê°œ",
            ""
        ]
        
        # ë©”íƒ€ë°ì´í„° ìš”ì•½ ì •ë³´ ì¶”ê°€ (ë” êµ¬ì²´ì )
        if metadata_summary:
            prompt_parts.extend([
                "== ë°ì´í„° ìš”ì•½ ì •ë³´ ==",
                f"â€¢ ì´ ë ˆì½”ë“œ: {metadata_summary.get('total_records', 0)}ê°œ",
                f"â€¢ ë°ì´í„° ìœ í˜•: {metadata_summary.get('data_types', {})}",
                f"â€¢ ë‚ ì§œ ë²”ìœ„: {metadata_summary.get('date_range', {})}",
                f"â€¢ ìˆ˜ëŸ‰ í†µê³„: {metadata_summary.get('quantity_stats', {})}",
                ""
            ])
        
        # ë¬¸ì„œ ì •ë³´ ì¶”ê°€ (ìƒìœ„ 3ê°œ)
        if documents:
            prompt_parts.append("== ê´€ë ¨ ë¬¸ì„œ ë‚´ìš© ==")
            for i, doc in enumerate(documents[:3], 1):
                prompt_parts.append(f"{i}. {doc.strip()}")
            prompt_parts.append("")
        
        # ì°¨íŠ¸ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if chart_data:
            prompt_parts.extend([
                "== ì§‘ê³„ëœ ì°¨íŠ¸ ë°ì´í„° ==",
                f"ì œëª©: {chart_data.get('title', 'N/A')}",
                f"ë°ì´í„°: {chart_data.get('data', [])}",
                f"ë¼ë²¨: {chart_data.get('labels', [])}",
                ""
            ])
        
        return "\n".join(prompt_parts)
    
    def _try_direct_answer(self, question: str) -> Optional[str]:
        """ê°„ë‹¨í•œ ì§ˆë¬¸ë“¤ì— ëŒ€í•´ ì§ì ‘ ê³„ì‚°í•˜ì—¬ ë‹µë³€"""
        if not self.data_service.data_loaded:
            return None
            
        question_lower = question.lower()
        
        try:
            # ì´ ì¬ê³ ëŸ‰ ì§ˆë¬¸
            if any(word in question_lower for word in ['ì´ ì¬ê³ ëŸ‰', 'ì´ì¬ê³ ', 'ì „ì²´ ì¬ê³ ', 'ì´ ì¬ê³ ']):
                if self.data_service.product_master is not None and 'í˜„ì¬ê³ ' in self.data_service.product_master.columns:
                    total_inventory = int(self.data_service.product_master['í˜„ì¬ê³ '].sum())
                    product_count = len(self.data_service.product_master)
                    return f"ğŸ¢ **ì´ ì¬ê³ ëŸ‰ì€ {total_inventory:,}ê°œì…ë‹ˆë‹¤.**\n\nğŸ“Š ì „ì²´ {product_count}ê°œ í’ˆëª©ì˜ í˜„ì¬ ì¬ê³ ë¥¼ í•©ê³„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\nğŸ’¡ ìì„¸í•œ ë™ë³„ ë¶„í¬ëŠ” 'ë™ë³„ ì¬ê³  í˜„í™©' ì°¨íŠ¸ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”."
                else:
                    return "ğŸ“Š ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ê³  ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
            
            # ì…ê³ ëŸ‰ ì§ˆë¬¸
            if any(word in question_lower for word in ['ì…ê³ ëŸ‰', 'ì…ê³  í˜„í™©', 'ì˜¤ëŠ˜ ì…ê³ ']):
                if self.data_service.inbound_data is not None and 'PalleteQty' in self.data_service.inbound_data.columns:
                    total_inbound = int(self.data_service.inbound_data['PalleteQty'].sum())
                    inbound_count = len(self.data_service.inbound_data)
                    return f"ğŸ“¦ **ì´ ì…ê³ ëŸ‰ì€ {total_inbound:,}ê°œì…ë‹ˆë‹¤.**\n\nğŸ“ˆ ì´ {inbound_count}ê±´ì˜ ì…ê³  ê¸°ë¡ì´ ìˆìŠµë‹ˆë‹¤.\nğŸ’¡ ìƒì„¸í•œ ì…ê³  íŠ¸ë Œë“œëŠ” 'ì¼ë³„ ì…ì¶œê³  íŠ¸ë Œë“œ' ì°¨íŠ¸ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”."
                else:
                    return "ğŸ“¦ ì£„ì†¡í•©ë‹ˆë‹¤. ì…ê³  ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ì¶œê³ ëŸ‰ ì§ˆë¬¸
            if any(word in question_lower for word in ['ì¶œê³ ëŸ‰', 'ì¶œê³  í˜„í™©', 'ì˜¤ëŠ˜ ì¶œê³ ']):
                if self.data_service.outbound_data is not None and 'PalleteQty' in self.data_service.outbound_data.columns:
                    total_outbound = int(self.data_service.outbound_data['PalleteQty'].sum())
                    outbound_count = len(self.data_service.outbound_data)
                    return f"ğŸšš **ì´ ì¶œê³ ëŸ‰ì€ {total_outbound:,}ê°œì…ë‹ˆë‹¤.**\n\nğŸ“‰ ì´ {outbound_count}ê±´ì˜ ì¶œê³  ê¸°ë¡ì´ ìˆìŠµë‹ˆë‹¤.\nğŸ’¡ ìƒì„¸í•œ ì¶œê³  íŠ¸ë Œë“œëŠ” 'ì¼ë³„ ì…ì¶œê³  íŠ¸ë Œë“œ' ì°¨íŠ¸ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”."
                else:
                    return "ğŸšš ì£„ì†¡í•©ë‹ˆë‹¤. ì¶œê³  ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ë™ ê´€ë ¨ ì§ˆë¬¸
            if any(word in question_lower for word in ['ë™', 'rack', 'aë™', 'bë™', 'cë™']):
                if self.data_service.product_master is not None and 'Rack Name' in self.data_service.product_master.columns:
                    rack_summary = self.data_service.product_master.groupby('Rack Name')['í˜„ì¬ê³ '].sum().sort_values(ascending=False)
                    if len(rack_summary) > 0:
                        rack_info = []
                        for rack, qty in rack_summary.head(5).items():
                            rack_info.append(f"â€¢ {rack}: {int(qty):,}ê°œ")
                        
                        return f"ğŸ¢ **ë™ë³„ ì¬ê³  í˜„í™©:**\n\n" + "\n".join(rack_info) + f"\n\nğŸ“Š ì´ {len(rack_summary)}ê°œ ë™ì— ì¬ê³ ê°€ ë¶„ì‚°ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
                    else:
                        return "ğŸ¢ ë™ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                else:
                    return "ğŸ¢ ì£„ì†¡í•©ë‹ˆë‹¤. ë™ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            print(f"ì§ì ‘ ë‹µë³€ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return None
        
        return None